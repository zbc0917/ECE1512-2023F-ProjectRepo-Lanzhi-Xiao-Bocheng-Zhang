{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzfmS9ZrYh0a"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzK42ol7YZow",
        "outputId": "8bd4a9bc-6a47-4af9-961d-f92ad6f30221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3aXgO0rZZKf",
        "outputId": "972dad0e-a06a-4405-b8c0-832d6155300f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/ECE1512/ProjectA/mhist_dataset/images.zip\", 'r')\n",
        "zip_ref.extractall(\"./\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLvoIJnAZd-R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten, Dense, Input, Lambda, Conv2D, MaxPooling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bkxCAYbbDZ3"
      },
      "source": [
        "# Load The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DHgdbIvbHZe"
      },
      "outputs": [],
      "source": [
        "from torch._C import Size\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "np.random.seed(32)\n",
        "\n",
        "def load_data(image_path, csv_path, split):\n",
        "    annotations = pd.read_csv(csv_path)\n",
        "    data = annotations[annotations['Partition'] == split].reset_index(drop=True)\n",
        "    return data, image_path\n",
        "\n",
        "def get_item(data, image_path, idx, transformer):\n",
        "    image_full_name = os.path.join(image_path, data.iloc[idx]['Image Name'])\n",
        "    x = Image.open(image_full_name)\n",
        "\n",
        "    if transformer:\n",
        "        x = transformer(x)\n",
        "        x = x.permute(1, 2, 0)\n",
        "\n",
        "    label = data.iloc[idx]['Majority Vote Label']\n",
        "    y = torch.tensor([1, 0]) if label == 'HP' else torch.tensor([0, 1])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def data_loader(data, image_path, transformer, batch_size, shuffle=True):\n",
        "    items = []\n",
        "    for idx in range(len(data)):\n",
        "        x, y = get_item(data, image_path, idx, transformer)\n",
        "        items.append((x, y))\n",
        "    return DataLoader(items, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "custom_transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "image_path = \"/content/images\"\n",
        "csv_path = \"/content/drive/MyDrive/ECE1512/ProjectA/mhist_dataset/annotations.csv\"\n",
        "\n",
        "train_data, train_image_path = load_data(image_path, csv_path, 'train')\n",
        "test_data, test_image_path = load_data(image_path, csv_path, 'test')\n",
        "\n",
        "\n",
        "train_loader = data_loader(train_data, train_image_path, custom_transformer, BATCH_SIZE)\n",
        "test_loader = data_loader(test_data, test_image_path, custom_transformer, BATCH_SIZE, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyUATDMtZiKM"
      },
      "source": [
        "# Load Model\n",
        "Load the pre-trained ResNet50V2 and MobileNetV2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGU6kVH6Z1ZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e381ddf-8534-4291-c011-f93573a1268c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102869336/102869336 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Teacher Model = ResNet50V2\n",
        "\n",
        "IMAGE_SIZE = (224, 224, 3)\n",
        "resnet_model = ResNet50V2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "\n",
        "#Freeze the Pre-traine ResNet50V2 for inital epochs\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_teacher = Dense(2, activation=None)(resnet_model.output)  # raw logits for binary classification\n",
        "last_teacher.trainable = True\n",
        "\n",
        "#Create the New Teacher Model\n",
        "teacher_model = Model(inputs=resnet_model.input, outputs=last_teacher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kF48rh-assE"
      },
      "outputs": [],
      "source": [
        "#Student Model = MobileNetV2\n",
        "mobilenet_model = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "\n",
        "for layer in mobilenet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_student = Dense(2, activation=None)(mobilenet_model.output)\n",
        "last_student.trainable = True\n",
        "\n",
        "student_model = Model(inputs=mobilenet_model.input, outputs=last_student)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Noa5rcerLUSR"
      },
      "outputs": [],
      "source": [
        "#Student Model from Scratch\n",
        "mobile_model_scratch = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "#freeze pre-trained mobilenet layers for initial epochs\n",
        "for layer in mobile_model_scratch.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Design the last dense layer\n",
        "x_student_scratch = Dense(2, activation=None)(mobile_model_scratch.output)\n",
        "x_student_scratch.trainable = True\n",
        "\n",
        "student_model_scratch = Model(inputs=mobile_model_scratch.input, outputs=x_student_scratch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nJZgDJncEhl"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbdXWPpXcIkH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "    \"\"\"Compute the teacher loss for given images and labels.\n",
        "\n",
        "    Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    logits = teacher_model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxG6jeky4KFP"
      },
      "outputs": [],
      "source": [
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4 #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits, student_logits, temperature = DISTILLATION_TEMPERATURE):\n",
        "\n",
        "    soft_targets = tf.nn.softmax(teacher_logits/temperature, axis = 1)\n",
        "\n",
        "    return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "\n",
        "    student_subclass_logits = student_model(images, training=True)\n",
        "    teacher_subclass_logits = teacher_model(images, training=False)\n",
        "    distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "    cross_entropy_loss_value = tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          labels, student_subclass_logits))\n",
        "\n",
        "    total_loss = cross_entropy_loss_value * ALPHA + (1 - ALPHA) * distillation_loss_value\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvcB2dWcjwb"
      },
      "source": [
        "#Train and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJNAMkSY62Kp"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS_INIT = 10\n",
        "NUM_EPOCHS_FT = 25\n",
        "NUM_CLASSES = 2\n",
        "LEARNING_RATE_REDUCTION_FACTOR = 10\n",
        "\n",
        "def compute_AUC(model, images, labels):\n",
        "    \"\"\"\n",
        "    Computes AUC for given model predictions and adjusts the logits if needed.\n",
        "    \"\"\"\n",
        "    class_logits = model(images, training=False)\n",
        "\n",
        "    # Adjust logits if they don't match the expected shape by splitting and summing\n",
        "    if class_logits.shape[1] != NUM_CLASSES:\n",
        "        split_data = tf.split(class_logits, [8, 8], axis=-1)\n",
        "        class_logits = tf.stack([tf.reduce_sum(i, axis=-1) for i in split_data], axis=-1)\n",
        "\n",
        "    scores = tf.nn.sigmoid(class_logits)\n",
        "\n",
        "    auc_metric = tf.keras.metrics.AUC()\n",
        "    auc_metric.reset_state()\n",
        "    auc_metric.update_state(labels, scores)\n",
        "    return auc_metric.result().numpy()\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn, learning_rate, train_loader, test_loader):\n",
        "    print('--- Start Initial Training Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Initial Training Phase\n",
        "    for epoch in range(1, NUM_EPOCHS_INIT + 1):\n",
        "        print('Epoch {}: '.format(epoch), end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Unfreeze all layers and fine-tune\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    print('\\n--- Start Fine-Tuning Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate/LEARNING_RATE_REDUCTION_FACTOR)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS_FT + 1):\n",
        "        print(f'Epoch {epoch}: ', end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    AUC_set = [compute_AUC(model, tf.convert_to_tensor(images.numpy()), tf.convert_to_tensor(labels.numpy()))\n",
        "               for images, labels in test_loader]\n",
        "    test_AUC = sum(AUC_set) / len(AUC_set) * 100\n",
        "    print(f'\\nTest AUC: {test_AUC:.2f}')\n",
        "    return test_AUC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8at9yeXTdsCr"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLYQjjl3dv1_",
        "outputId": "282d24d1-9d2a-4009-98a4-b98ecd35419d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training teacher model:\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 1363 calls to <function _BaseOptimizer._update_step_xla at 0x781f673730a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 1364 calls to <function _BaseOptimizer._update_step_xla at 0x781f673730a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 85.13\n"
          ]
        }
      ],
      "source": [
        "print('Training teacher model:')\n",
        "test_acc_teacher = train_and_evaluate(teacher_model, compute_teacher_loss, 1e-4, train_loader, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMcOpFQsrjrW",
        "outputId": "fbb748a3-391e-4870-f426-68a457c10bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Student model:\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 80.09\n"
          ]
        }
      ],
      "source": [
        "print('Training Student model:')\n",
        "test_acc_student = train_and_evaluate(student_model, compute_student_loss, 1e-3, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgSh57aXA-0I"
      },
      "source": [
        "# Test Accuracy vs. Tempreture Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SsK4hymA-Ic",
        "outputId": "3ba0fbd1-c041-4fb4-9529-09687a38d0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tune Hyperparameter for the student model\n",
            "=============a:0.2===t:1===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 1363 calls to <function _BaseOptimizer._update_step_xla at 0x7ba050292170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 1364 calls to <function _BaseOptimizer._update_step_xla at 0x7ba050292170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 74.68\n",
            "=============a:0.2===t:2===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 84.87\n",
            "=============a:0.2===t:4===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 84.64\n",
            "=============a:0.2===t:16===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 87.40\n",
            "=============a:0.2===t:32===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 87.76\n",
            "=============a:0.2===t:64===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 88.68\n",
            "=============a:0.5===t:1===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 87.72\n",
            "=============a:0.5===t:2===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 88.69\n",
            "=============a:0.5===t:4===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 88.83\n",
            "=============a:0.5===t:16===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 88.45\n",
            "=============a:0.5===t:32===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 87.29\n",
            "=============a:0.5===t:64===============\n",
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 87.37\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(88.82755367986618, 0.5, 0)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Tune Hyperparameter for the student model\")\n",
        "temperature_set = [1,2,4,16,32,64]\n",
        "alpha_set = [0.2,0.5,]\n",
        "test_auc_set = []\n",
        "best_acc = 0\n",
        "best_alpha = 0\n",
        "best_temperature = 0\n",
        "\n",
        "for a in alpha_set:\n",
        "  for temp in temperature_set:\n",
        "    print(f\"=============a:{a}===t:{temp}===============\")\n",
        "    mobile_model_tune = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "    #freeze pre-trained mobilenet layers for initial epochs\n",
        "    for layer in mobile_model_tune.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #Design the last dense layer\n",
        "    x_student = Dense(2,activation=None)(mobile_model_tune.output)\n",
        "    x_student.trainable = True\n",
        "\n",
        "    student_model_kd = Model(inputs=mobile_model_tune.input, outputs=x_student)\n",
        "\n",
        "    DISTILLATION_TEMPERATURE = temp\n",
        "    ALPHA = a\n",
        "    test_auc_i = train_and_evaluate(student_model, compute_student_loss, 1e-3, train_loader, test_loader)\n",
        "    if a==0.5:\n",
        "      test_auc_set.append(test_auc_i)\n",
        "    if test_auc_i > best_acc:\n",
        "      best_acc = test_auc_i\n",
        "      best_alpha = a\n",
        "      best_temperature = temp\n",
        "\n",
        "# Output the best accuracy and its corresponding alpha and temperature\n",
        "best_acc, best_alpha, best_temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4HAOwQb6SAQt",
        "outputId": "7c55d346-53e1-4c49-f688-f3f8f63d8cfb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(temperature_set, test_auc_set)\n",
        "\n",
        "plt.xticks(temperature_set)\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs. Temperature ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtQJgTcL4wzl"
      },
      "source": [
        "# Training Student from Scratch First"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR72dT3H434T",
        "outputId": "769359e8-45db-436a-ed8d-aa7a43cee715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 73.08\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "73.07740687843291"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "    student_subclass_logits = student_model_scratch(images, training=True)\n",
        "    cross_entropy_loss = tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          labels, student_subclass_logits))\n",
        "\n",
        "    return cross_entropy_loss\n",
        "\n",
        "train_and_evaluate(student_model_scratch, compute_plain_cross_entropy_loss, 1e-3, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ZEjU11SSGZ"
      },
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs)\n",
        "citation: Tokusumi (2020). flops_calculation.py.  keras_flops.https://github.com/tokusumi/keras-flops/blob/master/keras_flops/flops_calculation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYbBqAgrSX4k",
        "outputId": "fe172ec2-2160-4382-9d24-6a124b510400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================Teacher Model==================\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_conv[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (Ba  (None, 56, 56, 64)           256       ['pool1_pool[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (  (None, 56, 56, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4096      ['conv2_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
            "                                                                     'conv2_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 28, 28, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 28, 28, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 28, 28, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 28, 28, 256)          0         ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 28, 28, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)      (None, 28, 28, 256)          0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'conv2_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (Ba  (None, 28, 28, 256)          1024      ['conv2_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (  (None, 28, 28, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv3_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
            "                                                                     'conv3_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block4_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 14, 14, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 14, 14, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 14, 14, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 512)          0         ['conv3_block3_out[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 14, 14, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)      (None, 14, 14, 512)          0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv3_block4_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (Ba  (None, 14, 14, 512)          2048      ['conv3_block4_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (  (None, 14, 14, 512)          0         ['conv4_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131072    ['conv4_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv4_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_conv[0][0]', \n",
            "                                                                     'conv4_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block4_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block4_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block4_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block4_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block5_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block5_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block5_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block5_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block6_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block6_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block6_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 1024)           0         ['conv4_block5_out[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)      (None, 7, 7, 1024)           0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv4_block6_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (  (None, 7, 7, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524288    ['conv5_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
            "                                                                     'conv5_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalizatio  (None, 7, 7, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " post_relu (Activation)      (None, 7, 7, 2048)           0         ['post_bn[0][0]']             \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['post_relu[0][0]']           \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 2)                    2002      ['predictions[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25615802 (97.72 MB)\n",
            "Trainable params: 2002 (7.82 KB)\n",
            "Non-trainable params: 25613800 (97.71 MB)\n",
            "__________________________________________________________________________________________________\n",
            "==================Student Model====================\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 1280)                 0         ['out_relu[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 1281000   ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    2002      ['predictions[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3540986 (13.51 MB)\n",
            "Trainable params: 2002 (7.82 KB)\n",
            "Non-trainable params: 3538984 (13.50 MB)\n",
            "__________________________________________________________________________________________________\n",
            "==========Student Model from Scratch=============\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 1280)                 0         ['out_relu[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 1281000   ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    2002      ['predictions[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3540986 (13.51 MB)\n",
            "Trainable params: 2002 (7.82 KB)\n",
            "Non-trainable params: 3538984 (13.50 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
        "def get_flops(model, batch_size=None):\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "\n",
        "    # Wrap the model's call function in a tf.function\n",
        "    @tf.function\n",
        "    def model_forward(input_data):\n",
        "        return model(input_data)\n",
        "\n",
        "    # Get a concrete function\n",
        "    real_model = model_forward.get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
        "\n",
        "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
        "            run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops\n",
        "\n",
        "print(\"====================Teacher Model==================\")\n",
        "model = teacher_model\n",
        "model.summary()\n",
        "\n",
        "print(\"==================Student Model====================\")\n",
        "model = student_model\n",
        "model.summary()\n",
        "\n",
        "print(\"==========Student Model from Scratch=============\")\n",
        "model = student_model_scratch\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IT38DwtOTlB",
        "outputId": "48021ec1-b414-427d-8e73-2e0c618a6f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============FLop======================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py:5253: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher FLOPS: 223296578112\n",
            "Student FLOPS: 19258804800\n",
            "Student Scratch FLOPS: 19258804800\n"
          ]
        }
      ],
      "source": [
        "print(\"=============FLop======================\")\n",
        "flops = get_flops(teacher_model, 32)\n",
        "print(f\"Teacher FLOPS: {flops}\")\n",
        "flops = get_flops(student_model, 32)\n",
        "print(f\"Student FLOPS: {flops}\")\n",
        "flops = get_flops(model, 32)\n",
        "print(f\"Student Scratch FLOPS: {flops}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNtxYlYOIRlo"
      },
      "source": [
        "# XAI method to explain models\n",
        "ciation: Mohammadi, Seyedmahmoud. \"xai_utils.py.\" ECE1512_2022W_ProjectRepo, GitHub, 2023, https://github.com/RezaMohammadi99/ECE1512_2022W_ProjectRepo_Seyedmahmoud-Mohammadi/blob/main/Project_A/xai_utils.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcGGNixVIYDd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ciation: Mohammadi, Seyedmahmoud.\n",
        "\"xai_utils.py.\" ECE1512_2022W_ProjectRepo, GitHub, 2023,\n",
        "https://github.com/RezaMohammadi99/ECE1512_2022W_ProjectRepo_Seyedmahmoud-Mohammadi/blob/main/Project_A/xai_utils.py.\n",
        "\"\"\"\n",
        "import cv2\n",
        "from time import time\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow.keras.backend as K\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#############################\n",
        "\n",
        "\n",
        "def layer_finder(k_model, model_arch, pool_input=True):\n",
        "\n",
        "  '''\n",
        "  Returns a list of all of the last layers in each block of the model.\n",
        "\n",
        "    Parameters:\n",
        "      k_model (Keras model): Either a VGG or ResNet\n",
        "      model_arch (str): Either \"VGG\" or \"ResNet\"\n",
        "\n",
        "    Returns:\n",
        "      last_layers (list): A list of all of the last layers in each block of the\n",
        "      model.\n",
        "  '''\n",
        "\n",
        "  if type(model_arch) != str:\n",
        "    raise TypeError(\"Input argument \\\"model_arch\\\" must be a string that is\\\n",
        "                      either \\\"VGG\\\" or \\\"ResNet\\\".\")\n",
        "\n",
        "  last_layers = []\n",
        "  pool_flag=False\n",
        "  block_end_detected=False\n",
        "  first_layer=True\n",
        "  j=0\n",
        "\n",
        "  if model_arch == \"VGG\":\n",
        "\n",
        "    for layer in k_model.layers:\n",
        "      if type(layer) == tf.keras.layers.MaxPool2D:\n",
        "        last_layers.append(layer.name)\n",
        "\n",
        "  elif model_arch == \"ResNet\":\n",
        "\n",
        "\n",
        "    for i in range(len(k_model.layers)):\n",
        "      if i<j: continue\n",
        "      #print(k_model.layers[i])\n",
        "      if len(k_model.layers[i+1].output.get_shape()) < 4:\n",
        "        # only save a layer if the block before the end was a convolutional block\n",
        "            last_layers.append(k_model.layers[i].name)\n",
        "            break\n",
        "\n",
        "      if k_model.layers[i+1].output.get_shape()[2]<k_model.layers[i].output.get_shape()[2]-4:\n",
        "          if pool_input==True:\n",
        "              if type(k_model.layers[i]) == tf.keras.layers.InputLayer: continue\n",
        "              if 'ZeroPadding2D' in str(type(k_model.layers[i])):\n",
        "                  if type(k_model.layers[i-1]) == tf.keras.layers.InputLayer: continue\n",
        "                  last_layers.append(k_model.layers[i-1].name)\n",
        "              else:\n",
        "                  last_layers.append(k_model.layers[i].name)\n",
        "          else:\n",
        "              if first_layer:\n",
        "                  j=i+1\n",
        "                  pool_flag=True\n",
        "                  while(pool_flag):\n",
        "                      j += 1\n",
        "                      #print(str(type(k_model.layers[j])))\n",
        "                      if  'Conv2D' in str(type(k_model.layers[j])):\n",
        "                          #print('Here')\n",
        "                          last_layers.append(k_model.layers[j-1].name)\n",
        "                          first_layer=False\n",
        "                          pool_flag=False\n",
        "              else:\n",
        "                  j=i\n",
        "                  pool_flag=True\n",
        "                  while(pool_flag):\n",
        "                      j += 1\n",
        "                      #print(str(type(k_model.layers[j])))\n",
        "                      if 'merge.Add' in str(type(k_model.layers[j])):\n",
        "                          block_end_detected=True\n",
        "                          #print(j)\n",
        "                      elif block_end_detected==True and 'Conv2D' in str(type(k_model.layers[j])):\n",
        "                          #print('Here')\n",
        "                          last_layers.append(k_model.layers[j-1].name)\n",
        "                          block_end_detected=False\n",
        "                          pool_flag=False\n",
        "  else:\n",
        "\n",
        "    print(\"Input argument \\\"model_arch\\\" must be either \\\"VGG\\\" or \\\"ResNet\\\".\")\n",
        "\n",
        "  return [[lay] for lay in last_layers]\n",
        "def create_random_mask(h=7, w=7, H=224, W=224, p_1=0.5, resample=Image.BILINEAR):\n",
        "    '''\n",
        "    Generates one random mask utilized in RISE\n",
        "    inputs:\n",
        "        h, w: initial size of binary mask\n",
        "        H, W: final size of the upsampled mask\n",
        "        p_1: probability of actiating pixels in the down-sampled masks.\n",
        "        interp: upsampling technique.\n",
        "    returns:\n",
        "        mask: a smooth mask with the values in range [0,1] with size of HxW.\n",
        "    '''\n",
        "    assert H>h, 'Masks should be resized to higher dimensions.'\n",
        "    assert W>w, 'Masks should be resized to higher dimensions.'\n",
        "    # create random binary hxw mask\n",
        "    mask=np.random.choice([0, 1], size=(h, w), p=[1-p_1, p_1])\n",
        "\n",
        "    # upsample mask to (h+H,w+W)\n",
        "    mask = Image.fromarray(mask*255.)\n",
        "    mask = mask.resize((H + h, W + w), resample=resample)\n",
        "    mask = np.array(mask)\n",
        "\n",
        "    # randomly crop mask to HxW\n",
        "    w_crop = np.random.randint(0,w+1)\n",
        "    h_crop = np.random.randint(0,h+1)\n",
        "    mask = mask[h_crop:H + h_crop, w_crop:W + w_crop]\n",
        "\n",
        "    # normalize between 0 and 1\n",
        "    mask /= np.max(mask)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def create_attribution_masks(img, model, layers, class_index, max_mask_num, interp='bilinear'):\n",
        "    '''\n",
        "    Derives feature maps from one, or a couple of layers, and post-processes them\n",
        "    to convert them to attribution masks.\n",
        "\n",
        "    inputs:\n",
        "        img: a 4-D tensor image.\n",
        "        model: the classification model\n",
        "        layers: list of layers to be visualized either individually or mutually.\n",
        "        class_index: the output class according to whom the layer(s) are visualized.\n",
        "        max_mask_num: the threshold \"normalized gradient\" value for sampling attribution masks (\\mu in our paper)\n",
        "        interp: upsampling technique.\n",
        "        For now, 'bilinear' and 'nearest' are supported.\n",
        "    returns:\n",
        "        masks: a set of attribution masks normalized between 0 and 1.\n",
        "    '''\n",
        "    assert interp in ['bilinear', 'nearest'], 'Selected upsampling type undefined or unsupported.'\n",
        "    # Forward pass to get attribution masks.\n",
        "    conv_outputs=[]\n",
        "    for layer in model.layers:\n",
        "        if np.isin(layer.name,layers):\n",
        "            conv_outputs.append(layer.output)\n",
        "    conv_outputs.append(model.output)\n",
        "    feedforward1=keras.models.Model([model.input], [conv_outputs])\n",
        "    with tf.GradientTape() as tape:\n",
        "        ff_results=feedforward1([img])[0]\n",
        "        all_fmap_masks, predictions = ff_results[:-1], ff_results[-1]\n",
        "        loss = predictions[:, class_index]\n",
        "    grads = tape.gradient(loss, all_fmap_masks)\n",
        "    ###\n",
        "\n",
        "    # upsample and normalize masks.\n",
        "    num_masks=0\n",
        "    masks=[]\n",
        "    for i in range(len(layers)):\n",
        "        tmp_mask = all_fmap_masks[i][0].numpy()\n",
        "        if len(img.shape)==3:\n",
        "            axis=0\n",
        "            size=img.shape[1:]\n",
        "            tmp_mask = np.expand_dims(tmp_mask, axis=1)\n",
        "        elif len(img.shape)==4:\n",
        "            axis=(0,1)\n",
        "            size=img.shape[1:-1]\n",
        "        significance = np.mean(grads[i][0], axis=axis)\n",
        "        #idxs = np.argpartition(significance, -1*max_mask_num)[-1*max_mask_num:]\n",
        "        idxs = np.where(significance>max_mask_num*np.max(significance))[0]\n",
        "        if interp == 'bilinear':\n",
        "            fmap = tf.image.resize(tmp_mask[...,idxs], size, method='bilinear').numpy()\n",
        "        elif interp == 'nearest':\n",
        "            fmap = tf.image.resize(tmp_mask[...,idxs], size, method='nearest').numpy()\n",
        "        else: raise ValueError('You have selected an unsupported interpolation type.')\n",
        "\n",
        "        num_masks+=fmap.shape[2]\n",
        "        fmap -= np.min(fmap, axis=(0,1))\n",
        "        fmap /= (np.max(fmap, axis=(0,1))+10e-7)\n",
        "        masks.append(fmap)\n",
        "    return masks\n",
        "\n",
        "def visualize_layers(img, model, class_index, masks, H=224, W=224, C=3, batch_size = 128):\n",
        "    '''\n",
        "    Combines attribution masks using the RISE-based framework mentioned in\n",
        "    SISE white paper.\n",
        "    inputs:\n",
        "        img: a 3-D tensor image.\n",
        "        model: the classification model\n",
        "        class_index: the output class according to whom the layer(s) are visualized.\n",
        "        masks: a set of attribution masks normalized between 0 and 1.\n",
        "    returns:\n",
        "        sum_masks: visualization map of the selected layer(s).\n",
        "    This function follows 'create_attribution_masks()'.\n",
        "    '''\n",
        "    # creates perturbed images to probe model.\n",
        "    img = img if len(img.shape)==3 else np.expand_dims(img, axis=1)\n",
        "    X = np.einsum('hwc,hwn->nhwc', img, masks)\n",
        "    # second forward pass to valuate attribution maps\n",
        "    preds_masked = np.empty([0])\n",
        "    if masks.shape[2] <= batch_size :\n",
        "      preds_masked=np.append(preds_masked, model(X, training=False)[:,class_index],axis=0)\n",
        "    else :\n",
        "      for i in range (0, masks.shape[2]-batch_size, batch_size) :\n",
        "        preds_masked=np.append(preds_masked, model(X[i:i+batch_size], training=False)[:,class_index],axis=0)\n",
        "      preds_masked=np.append(preds_masked, model(X[i+batch_size:], training=False)[:,class_index],axis=0)\n",
        "\n",
        "    # Linear combination of attribution masks.\n",
        "    masks /= (masks.sum(axis=(0,1))+10e-7)\n",
        "    sum_mask = np.einsum('hwn,n->hw', masks, preds_masked)\n",
        "\n",
        "    sum_mask -= np.min(sum_mask)\n",
        "    sum_mask /= np.max(sum_mask)\n",
        "    return sum_mask\n",
        "\n",
        "def otsu(I, nbins=256, tau=1.5):\n",
        "    '''\n",
        "    Finds the optimum adaptive threshold value for a 2-D image.\n",
        "    inputs:\n",
        "        I: a 2-D image (visualization map/ heat-map/ etc.)\n",
        "        nbins: resolution of histogram. Increasing this parameter yields to more\n",
        "        precise threshold value, achieved in longer time.\n",
        "        tau: bottleneck amplititude\n",
        "        returns: Otsu adaptive threshold value\n",
        "    '''\n",
        "    I = np.round(I*nbins)\n",
        "    #histogram of the image\n",
        "    hist, bins = np.histogram(I.ravel(),nbins,[0,nbins])\n",
        "    #CDF/ mean/ variance terms for multiple values\n",
        "    i = np.arange(nbins)\n",
        "    varsb = np.zeros(nbins)\n",
        "    for j in range(1, nbins):\n",
        "        w0 = np.sum(hist[0:j])\n",
        "        w1 = np.sum(hist[j:nbins])\n",
        "        u0 = np.sum(np.multiply(hist[0:j], i[0:j])) / w0\n",
        "        u1 = np.sum(np.multiply(hist[j:nbins], i[j:nbins])) / w1\n",
        "        varsb[j] = w0 * w1 * (u0-u1) * (u0-u1)\n",
        "    # the threshold value is the one maximizing the variance term.\n",
        "    t = np.argmax(varsb)\n",
        "    #print(t)\n",
        "    k = round(t*tau)\n",
        "    if np.sum(hist[int(k):256]) < .1 * np.sum(hist):\n",
        "        #print('happened')\n",
        "        return t*tau/nbins\n",
        "    else:\n",
        "        return t/nbins\n",
        "\n",
        "def otsu_sigmoid(I, nbins=256, T=100., tau=1.5):\n",
        "    '''\n",
        "        Thresholds the 2-D visualization map softly, combining Otsu's method and\n",
        "        sigmoid function.\n",
        "        inputs:\n",
        "            I: a 2-D image (visualization map/ heat-map/ etc.)\n",
        "            nbins: resolution of histogram. Increasing this parameter yields to more\n",
        "            precise threshold value, achieved in longer time.\n",
        "            T: sigmoid temparature (preferred to be set to high values.)\n",
        "        returns:\n",
        "            the soft-thresholded heat-map according to the input.\n",
        "    '''\n",
        "    thr=otsu(I, nbins=256, tau=1.5)\n",
        "    return 1/(1 + np.exp(-(I-thr)*T))\n",
        "\n",
        "def fuse_visualization_maps(exmaps, fusion_type='otsu', T=100.):\n",
        "    '''\n",
        "    Fuses visualization maps to a unique explanation map. Visualization maps should\n",
        "    be given with the correct order (low-level layer to high-level layer)\n",
        "\n",
        "    '''\n",
        "    assert fusion_type in ['simple', 'otsu']\n",
        "    ex=exmaps[0]\n",
        "    if fusion_type=='simple':\n",
        "        for i in range(1, len(exmaps)):\n",
        "            ex += exmaps[i]\n",
        "            ex *= exmaps[i]\n",
        "    elif fusion_type=='otsu':\n",
        "        for i in range(1, len(exmaps)):\n",
        "            ex += exmaps[i]\n",
        "            ex *= otsu_sigmoid(exmaps[i], T=T)\n",
        "    return ex\n",
        "\n",
        "def SISE(img, model, class_index, layers, grad_thr, interp='bilinear',\n",
        "         fusion_type='otsu', T=100.):\n",
        "\n",
        "    '''\n",
        "    For now, this function supports VGG16, ResNet50, and ResNet101.\n",
        "    img: a 4-D image, or a 3-D array.\n",
        "    model: the classification model\n",
        "    layers: list of layers to be visualized either individually or mutually.\n",
        "    interp: upsampling technique.\n",
        "    Check the supproted upsampling types in function 'create_attribution_masks'.\n",
        "\tgrad_thr: Threshold on the average gradient values to select the most appropriate feature maps.\n",
        "    fusion_type: the fusion technipue for visualization maps:\n",
        "        simple: Using only addition and multiplication blocks.\n",
        "        otsu: Using addition, soft otsu threshold, and multiplication blocks.\n",
        "    auto_layer_finder: if 'True', the layers are automatically selected. Otherwise,\n",
        "        pre-defined layers for the models experimented are used.\n",
        "    pool_input_select: If True, the inputs of pooling layers are detected automatically.\n",
        "        Otherwise,  the outputs of pooling layers are detected automatically.\n",
        "        If 'auto_layer_finder=False', this parameter is ineffective.\n",
        "    '''\n",
        "    masks = create_attribution_masks(img, model, layers, class_index=class_index, max_mask_num = grad_thr, interp=interp)\n",
        "    exmaps=[]\n",
        "    for mask_set in masks:\n",
        "        exmaps.append(visualize_layers(img[0], model, class_index, mask_set))\n",
        "    return fuse_visualization_maps(exmaps, fusion_type=fusion_type, T=T)\n",
        "\n",
        "\n",
        "def weighted_fusion(w,exmaps, T=100.):\n",
        "    '''\n",
        "    Objective: weighted fusion using weighted addition, unweighted multiplication, and otsu threshold blocks.\n",
        "    inputs:\n",
        "        w: an array of weight factors of length N-1.\n",
        "        exmaps: a 3-D array of explanation maps of length H x W x N.\n",
        "    parameters:\n",
        "        N: number of visualiation maps received\n",
        "        H x W: size of visualization maps.\n",
        "    outputs:\n",
        "        e_out: fused explanation map.\n",
        "    '''\n",
        "    #w_post=np.maximum(w,0)\n",
        "    w_post=np.clip(a=w, a_min=0, a_max=2)\n",
        "    e23=np.multiply((exmaps[:,:,0]*w_post[0]+exmaps[:,:,1]*(2-w_post[0])),\n",
        "                    otsu_sigmoid(exmaps[:,:,1], T=T))\n",
        "    e234=np.multiply((e23*w_post[1]+exmaps[:,:,2]*(2-w_post[1])),\n",
        "                    otsu_sigmoid(exmaps[:,:,2], T=T))\n",
        "    e2345=np.multiply((e234*w_post[2]+exmaps[:,:,3]*(2-w_post[2])),\n",
        "                    otsu_sigmoid(exmaps[:,:,3], T=T))\n",
        "    e23456=np.multiply((e2345*w_post[3]+exmaps[:,:,4]*(2-w_post[3])),\n",
        "                    otsu_sigmoid(exmaps[:,:,4], T=T))\n",
        "    e_out = e23456\n",
        "    return e_out\n",
        "\n",
        "def grad_cam(input_model, image, layer_name):\n",
        "    cls = np.argmax(input_model.predict(image))\n",
        "    def normalize(x):\n",
        "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
        "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
        "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
        "    y_c = input_model.output\n",
        "    conv_output = input_model.get_layer(layer_name).output\n",
        "    feedforward1 = keras.models.Model([input_model.input], [conv_output, y_c])\n",
        "    with tf.GradientTape() as tape:\n",
        "        ff_results=feedforward1([image])\n",
        "        all_fmap_masks, predictions = ff_results[0], ff_results[-1]\n",
        "        loss = predictions[:, cls]\n",
        "    grads_val = tape.gradient(loss, all_fmap_masks)\n",
        "    if len(image.shape)==3:\n",
        "        axis=(0, 1)\n",
        "    elif len(image.shape)==4:\n",
        "        axis=(0, 1, 2)\n",
        "    weights = np.mean(grads_val, axis=axis)\n",
        "    cam = np.dot(all_fmap_masks[0], weights)\n",
        "    H,W= image.shape[1:3]\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = zoom(cam,H/cam.shape[0])\n",
        "    cam = cam / cam.max()\n",
        "    return cam\n",
        "\n",
        "def RISE(img, model, class_index, N_MASKS=8000, H=224, W=224, C=3):\n",
        "    '''\n",
        "\timg: a 3-D input image\n",
        "\tmodel: a trained model\n",
        "\tclass_index; The class of interest\n",
        "\tN_MASKS: The number of random masks to be generated\n",
        "\tH,W,C: The desired dimensions of the random masks\n",
        "\t'''\n",
        "    X = np.zeros(shape=(N_MASKS, H, W, C), dtype=np.float32)\n",
        "    masks = np.zeros((N_MASKS,H,W), dtype=np.float32)\n",
        "    #for i in tqdm(range(N_MASKS)):\n",
        "    for i in range(N_MASKS):\n",
        "        m =create_random_mask(H=H, W=W)\n",
        "        masks[i] = m\n",
        "        x = img.copy()\n",
        "\n",
        "        x[:, :, 0] *= m\n",
        "        #x[:, :, 1] *= m\n",
        "        #x[:, :, 2] *= m\n",
        "        X[i] = x\n",
        "    preds_masked = model.predict(X, verbose=0)\n",
        "    sum_mask = np.zeros(masks[0].shape, dtype=np.float32)\n",
        "\n",
        "    # np.einsum???\n",
        "    for i, mask in enumerate(masks):\n",
        "        m = mask * preds_masked[i, class_index]\n",
        "        sum_mask += m\n",
        "\n",
        "    sum_mask -= np.min(sum_mask)\n",
        "    sum_mask /= np.max(sum_mask)\n",
        "    return sum_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QPV_qiuUOLF"
      },
      "outputs": [],
      "source": [
        "k = 0\n",
        "index = 0\n",
        "for next_batch in train_loader:\n",
        "    #print(np.array(next_batch[0]).shape)   #image\n",
        "    image_batch = next_batch[0]\n",
        "    image_batch = tf.convert_to_tensor(image_batch)\n",
        "    prediction_teacher = teacher_model.predict(image_batch)\n",
        "    prediction_student = student_model.predict(image_batch)\n",
        "    label = next_batch[1]\n",
        "    #print(np.array(next_batch[1]).shape)   #label\n",
        "\n",
        "    img = np.array(image_batch[index])\n",
        "\n",
        "    explanation_map_RISE1 = RISE(img, teacher_model, class_index=np.argmax(prediction_teacher[index]) ,N_MASKS=1000,H=224, W=224, C=3)  #\n",
        "    explanation_map_RISE1 -= explanation_map_RISE1.min()\n",
        "    explanation_map_RISE1 /= explanation_map_RISE1.max()+10e-30\n",
        "\n",
        "    explanation_map_RISE2 = RISE(img, student_model, class_index=np.argmax(prediction_student[index]) ,N_MASKS=1000,H=224, W=224, C=3)\n",
        "    explanation_map_RISE2 -= explanation_map_RISE2.min()\n",
        "    explanation_map_RISE2 /= explanation_map_RISE2.max()+10e-30\n",
        "\n",
        "    explanation_map_RISE3 = RISE(img, student_model_scratch, class_index=np.argmax(prediction_student[index]) ,N_MASKS=1000,H=224, W=224, C=3)\n",
        "    explanation_map_RISE3 -= explanation_map_RISE3.min()\n",
        "    explanation_map_RISE3 /= explanation_map_RISE3.max()+10e-30\n",
        "\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(img[:,:,0])\n",
        "    plt.axis('off')\n",
        "    plt.title('Sample image')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(img[:,:,0])\n",
        "    plt.imshow(explanation_map_RISE1, cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title('Explanation map teacher)')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(img[:,:,0])\n",
        "    plt.imshow(explanation_map_RISE2, cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title('Explanation map student with KD')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(img[:,:,0])\n",
        "    plt.imshow(explanation_map_RISE3, cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title('Explanation map student without KD')\n",
        "    plt.show()\n",
        "\n",
        "    k += 1\n",
        "    print(k)\n",
        "    if k == 10:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mHwmKfWLbQ"
      },
      "source": [
        "# Implementing the state-of-the-art KD algorithm (Part a)\n",
        "Choose paper of citation 15: Subclass_Knowledge_Distillation_with_Known_Subclass_Labels.pdf\n",
        "using the skd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwS0KnpaWP_i"
      },
      "outputs": [],
      "source": [
        "from torch._C import Size\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_data_skd(image_path, csv_path, split):\n",
        "    annotations = pd.read_csv(csv_path)\n",
        "    data = annotations[annotations['Partition'] == split].reset_index(drop=True)\n",
        "    return data, image_path\n",
        "\n",
        "def get_item_skd(data, image_path, idx, transformer):\n",
        "    image_full_name = os.path.join(image_path, data.iloc[idx]['Image Name'])\n",
        "    x = Image.open(image_full_name)\n",
        "\n",
        "    if transformer:\n",
        "        x = transformer(x)\n",
        "        x = x.permute(1, 2, 0)\n",
        "\n",
        "    annotator_count = data.iloc[idx]['Number of Annotators who Selected SSA (Out of 7)']\n",
        "    if annotator_count <= 1:\n",
        "\n",
        "      y = torch.tensor([1, 0, 0, 0]) # Strongly Disagree\n",
        "    elif annotator_count <= 3:\n",
        "      y = torch.tensor([0, 1, 0, 0]) # Disagree\n",
        "    elif annotator_count <= 5:\n",
        "      y = torch.tensor([0, 0, 1, 0]) # Agree\n",
        "    else:\n",
        "      y = torch.tensor([0, 0, 0, 1]) # Strongly Agree\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def data_loader_skd(data, image_path, transformer, batch_size, shuffle=True):\n",
        "    items = []\n",
        "    for idx in range(len(data)):\n",
        "        x, y = get_item_skd(data, image_path, idx, transformer)\n",
        "        items.append((x, y))\n",
        "    return DataLoader(items, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "custom_transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "image_path = \"/content/images\"\n",
        "csv_path = \"/content/drive/MyDrive/ECE1512/ProjectA/mhist_dataset/annotations.csv\"\n",
        "\n",
        "train_data_skd, train_image_path = load_data_skd(image_path, csv_path, 'train')\n",
        "test_data_skd, test_image_path = load_data_skd(image_path, csv_path, 'test')\n",
        "\n",
        "\n",
        "train_loader_skd = data_loader_skd(train_data_skd, train_image_path, custom_transformer, BATCH_SIZE)\n",
        "test_loader_skd = data_loader_skd(test_data_skd, test_image_path, custom_transformer, BATCH_SIZE, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAyzegRrWoPH"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (224, 224, 3)\n",
        "# Initialize ResNet50V2 with ImageNet weights\n",
        "resnet_model = ResNet50V2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "\n",
        "# Freeze the pre-trained ResNet50V2 layers for initial epochs\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Design the last dense layer for the teacher model\n",
        "last_teacher = Dense(4, activation=None)(resnet_model.output)  # raw logits for binary classification\n",
        "last_teacher.trainable = True\n",
        "\n",
        "# Create the new teacher model\n",
        "teacher_model_skd = Model(inputs=resnet_model.input, outputs=last_teacher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX7riQHAWqTQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.nn_ops import softmax\n",
        "# Initialize MobileNetV2 with ImageNet weights\n",
        "mobilenet_model = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "\n",
        "# Freeze the pre-trained MobileNetV2 layers for initial epochs\n",
        "for layer in mobilenet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Design the last dense layer\n",
        "last_student = Dense(4, activation=None)(mobilenet_model.output)  # raw logits for binary classification\n",
        "last_student.trainable = True\n",
        "\n",
        "# Create the new model\n",
        "student_model_skd = Model(inputs=mobilenet_model.input, outputs=last_student)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk3tfgwK6CvS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def compute_teacher_loss_skd(images, labels):\n",
        "    \"\"\"Compute the teacher loss for given images and labels.\n",
        "\n",
        "    Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    logits = teacher_model_skd(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AlQodz-Wubj"
      },
      "outputs": [],
      "source": [
        "def compute_student_loss_skd(images, labels):\n",
        "    \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "       and labels.\n",
        "\n",
        "    Args:\n",
        "      images: Tensor representing a batch of images.\n",
        "      labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "      Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    student_subclass_logits = student_model_skd(images, training=True)\n",
        "    teacher_subclass_logits = teacher_model_skd(images, training=False)\n",
        "\n",
        "    student_predictions = tf.nn.sigmoid(student_subclass_logits)\n",
        "    teacher_predictions = tf.nn.sigmoid(teacher_subclass_logits)\n",
        "\n",
        "    # Compute Hamming distance between teacher and student one-hot vectors\n",
        "    hamming_distance = tf.math.abs(student_predictions - teacher_predictions)\n",
        "\n",
        "    # Assign weights based on Hamming distance\n",
        "    weights = tf.where(hamming_distance == 1, 1.0,  # 1x weight for distance of 1\n",
        "                       tf.where(hamming_distance == 2, 1.5,  # 2x weight for distance of 2\n",
        "                                0.0))  # 0 weight for distance of 0\n",
        "\n",
        "    distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "    # Adjust distillation loss based on weights\n",
        "    distillation_loss_value = distillation_loss_value * tf.reduce_mean(weights)\n",
        "\n",
        "    # Compute cross-entropy loss with hard targets.\n",
        "    cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_subclass_logits))\n",
        "\n",
        "    # Combine the cross-entropy loss and distillation loss.\n",
        "    total_loss = ALPHA *  cross_entropy_loss_value + (1.0 - ALPHA) * distillation_loss_value\n",
        "\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOYhd1XvWyMz"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS_INIT = 10\n",
        "NUM_EPOCHS_FT = 25\n",
        "NUM_CLASSES = 4\n",
        "LEARNING_RATE_REDUCTION_FACTOR = 10\n",
        "\n",
        "def compute_auc_skd(model, images, labels):\n",
        "    \"\"\"\n",
        "    Computes AUC for given model predictions and adjusts the logits if needed.\n",
        "    \"\"\"\n",
        "    class_logits = model(images, training=False)\n",
        "\n",
        "    # Adjust logits if they don't match the expected shape by splitting and summing\n",
        "    if class_logits.shape[1] != NUM_CLASSES:\n",
        "        split_data = tf.split(class_logits, [8, 8], axis=-1)\n",
        "        class_logits = tf.stack([tf.reduce_sum(i, axis=-1) for i in split_data], axis=-1)\n",
        "\n",
        "    scores = tf.nn.sigmoid(class_logits)\n",
        "\n",
        "    auc_metric = tf.keras.metrics.AUC()\n",
        "    auc_metric.reset_state()\n",
        "    auc_metric.update_state(labels, scores)\n",
        "\n",
        "    return auc_metric.result().numpy()\n",
        "\n",
        "def train_and_evaluate_skd(model, compute_loss_fn, learning_rate, train_loader, test_loader):\n",
        "    print('--- Start Initial Training Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Initial Training Phase\n",
        "    for epoch in range(1, NUM_EPOCHS_INIT + 1):\n",
        "        print(f'Epoch {epoch}: ', end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Unfreeze all layers and fine-tune\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    print('\\n--- Start Fine-Tuning Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate / LEARNING_RATE_REDUCTION_FACTOR)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS_FT + 1):\n",
        "        print(f'Epoch {epoch}: ', end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Evaluation\n",
        "    AUC_set = [compute_auc_skd(model, tf.convert_to_tensor(images.numpy()), tf.convert_to_tensor(labels.numpy()))\n",
        "               for images, labels in test_loader]\n",
        "    test_AUC = sum(AUC_set) / len(AUC_set) * 100\n",
        "    print(f'\\nTest AUC: {test_AUC:.2f}')\n",
        "\n",
        "    return test_AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_teacher_skd = train_and_evaluate_skd(teacher_model_skd, compute_teacher_loss_skd, 1e-4, train_loader_skd, test_loader_skd)"
      ],
      "metadata": {
        "id": "cdOHtarJ6N5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ScWadBAW1wZ",
        "outputId": "459f1146-798a-4009-ef0d-4a3ad5076d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 82.17\n"
          ]
        }
      ],
      "source": [
        "test_acc_student_skd = train_and_evaluate_skd(student_model_skd, compute_student_loss_skd, 1e-3, train_loader_skd, test_loader_skd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV2Zklt_JVCw"
      },
      "source": [
        "# Implementing the state-of-the-art KD algorithm (Part b)\n",
        "Choose to read the paper with citation 9: Improved Knowledge Distillation via Teacher Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_LdYcOUSgjw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_data_skd(image_path, csv_path, split):\n",
        "    annotations = pd.read_csv(csv_path)\n",
        "    data = annotations[annotations['Partition'] == split].reset_index(drop=True)\n",
        "    return data, image_path\n",
        "\n",
        "def get_item_skd(data, image_path, idx, transformer):\n",
        "    image_full_name = os.path.join(image_path, data.iloc[idx]['Image Name'])\n",
        "    x = Image.open(image_full_name)\n",
        "\n",
        "    if transformer:\n",
        "        x = transformer(x)\n",
        "        x = x.permute(1, 2, 0)\n",
        "\n",
        "    label = data.iloc[idx][\"Majority Vote Label\"]\n",
        "    if label == 'HP':\n",
        "        y = torch.tensor([1, 0, 0, 0, 0])\n",
        "    else:\n",
        "      annotator_count = data.iloc[idx]['Number of Annotators who Selected SSA (Out of 7)']\n",
        "      if annotator_count <= 4:\n",
        "        y = torch.tensor([0, 1, 0, 0, 0]) # hard to detect\n",
        "      elif annotator_count == 5:\n",
        "        y = torch.tensor([0, 0, 1, 0, 0]) # med\n",
        "      elif annotator_count == 6:\n",
        "        y = torch.tensor([0, 0, 0, 1, 0]) # med-well\n",
        "      else:\n",
        "        y = torch.tensor([0, 0, 0, 0, 1]) # easy\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def data_loader_skd(data, image_path, transformer, batch_size, shuffle=True):\n",
        "    items = []\n",
        "    for idx in range(len(data)):\n",
        "        x, y = get_item_skd(data, image_path, idx, transformer)\n",
        "        items.append((x, y))\n",
        "    return DataLoader(items, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "custom_transformer = transforms.Compose([\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "custom_transformer_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "image_path = \"/content/images\"\n",
        "csv_path = \"/content/drive/MyDrive/ECE1512/ProjectA/mhist_dataset/annotations.csv\"\n",
        "\n",
        "train_data_takd, train_image_path = load_data_skd(image_path, csv_path, 'train')\n",
        "test_data_takd, test_image_path = load_data_skd(image_path, csv_path, 'test')\n",
        "\n",
        "\n",
        "train_loader_takd = data_loader_skd(train_data_takd, train_image_path, custom_transformer, BATCH_SIZE)\n",
        "test_loader_takd = data_loader_skd(test_data_takd, test_image_path, custom_transformer_test, BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nltcYRrKGuS",
        "outputId": "55a9ff42-6695-4545-9f43-1afcfc6a8488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102869336/102869336 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Teacher Model = ResNet50V2\n",
        "NUM_CLASSES = 5\n",
        "IMAGE_SIZE = (224, 224, 3)\n",
        "resnet_model_takd = ResNet50V2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "\n",
        "#Freeze the Pre-traine ResNet50V2 for inital epochs\n",
        "for layer in resnet_model_takd.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(resnet_model_takd.output)\n",
        "last_teacher = Dense(NUM_CLASSES, activation=None)(x)  # raw logits for binary classification\n",
        "last_teacher.trainable = True\n",
        "\n",
        "#Create the New Teacher Model\n",
        "teacher_model_takd = Model(inputs=resnet_model_takd.input, outputs=last_teacher)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Teacher Assistant (TA) model = DenseNet\n",
        "dense_model_takd = tf.keras.applications.DenseNet121(include_top=True, weights='imagenet',input_shape=IMAGE_SIZE)\n",
        "for layer in dense_model_takd.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_ta = Dense(NUM_CLASSES, activation=None)(dense_model_takd.output)  # raw logits for binary classification\n",
        "last_ta.trainable = True\n",
        "ta_model_takd = Model(inputs = dense_model_takd.input, outputs = last_ta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1aTSt9lcOZ3",
        "outputId": "fdedc577-32a5-4886-d470-a5d2c4bc94e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
            "33188688/33188688 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Student Model = MobileNetV2\n",
        "mobilenet_model_takd = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "for layer in mobilenet_model_takd.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_student = Dense(NUM_CLASSES, activation=None)(mobilenet_model_takd.output)\n",
        "last_student.trainable = True\n",
        "\n",
        "student_model_takd = Model(inputs=mobilenet_model_takd.input, outputs=last_student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJt9OqlXcQHM",
        "outputId": "b6cbb68b-ed63-4036-9f3d-a8102c899851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DOGLmIdJssl"
      },
      "outputs": [],
      "source": [
        "#Teacher Loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_teacher_loss_takd(images, labels):\n",
        "\n",
        "    subclass_logits = teacher_model_takd(images, training=True)\n",
        "    probability = tf.nn.softmax(subclass_logits)\n",
        "\n",
        "    # # Compute the softmax cross-entropy loss\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,subclass_logits))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY--3igAvs_p"
      },
      "outputs": [],
      "source": [
        "#TA Loss\n",
        "def takd_loss(student_logits, teacher_logits, T=1):\n",
        "    # Soften the logits\n",
        "    student_probs = tf.nn.softmax(student_logits / T)\n",
        "    teacher_probs = tf.nn.softmax(teacher_logits / T)\n",
        "    return tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits(\n",
        "            teacher_logits, student_logits / T)) * T ** 2\n",
        "\n",
        "#TA Loss\n",
        "def compute_ta_loss_takd(images, labels, lamb=0.5, T=4):\n",
        "    teacher_logits = teacher_model_takd(images, training=False)\n",
        "    ta_logits = ta_model_takd(images, training = True)\n",
        "\n",
        "    L_skd = takd_loss(ta_logits, teacher_logits, T)\n",
        "    L_ce =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,ta_logits))\n",
        "    loss = lamb * L_ce + (1 - lamb) * L_skd\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w-Vc1z3JhxJ"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "#Student Loss\n",
        "def compute_student_loss_takd(images, labels, lamb=0.5, T=4):\n",
        "    teacher_logits = ta_model_takd(images, training=False)\n",
        "    student_logits = student_model_takd(images, training = True)\n",
        "\n",
        "    L_takd = takd_loss(student_logits, teacher_logits, T)\n",
        "    L_ce =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_logits))\n",
        "    loss = lamb * L_ce + (1 - lamb) * L_takd\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YWUCtExXYqe"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS_INIT = 10\n",
        "NUM_EPOCHS_FT = 25\n",
        "NUM_CLASSES = 5\n",
        "LEARNING_RATE_REDUCTION_FACTOR = 10\n",
        "def compute_auc_takd(model, images, labels):\n",
        "    \"\"\"\n",
        "    Computes AUC for given model predictions and adjusts the logits if needed.\n",
        "    \"\"\"\n",
        "    class_logits = model(images, training=False)\n",
        "\n",
        "    # Adjust logits if they don't match the expected shape by splitting and summing\n",
        "    if class_logits.shape[1] != NUM_CLASSES:\n",
        "        split_data = tf.split(class_logits, [8, 8], axis=-1)\n",
        "        class_logits = tf.stack([tf.reduce_sum(i, axis=-1) for i in split_data], axis=-1)\n",
        "\n",
        "    scores = tf.nn.sigmoid(class_logits)\n",
        "\n",
        "    auc_metric = tf.keras.metrics.AUC()\n",
        "    auc_metric.reset_state()\n",
        "    auc_metric.update_state(labels, scores)\n",
        "\n",
        "    return auc_metric.result().numpy()\n",
        "\n",
        "def train_and_evaluate_takd(model, compute_loss_fn, learning_rate, train_loader, test_loader):\n",
        "    print('--- Start Initial Training Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Initial Training Phase\n",
        "    for epoch in range(1, NUM_EPOCHS_INIT + 1):\n",
        "        print(f'Epoch {epoch}: ', end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Unfreeze all layers and fine-tune\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    print('\\n--- Start Fine-Tuning Epochs ---')\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate / LEARNING_RATE_REDUCTION_FACTOR)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS_FT + 1):\n",
        "        print(f'Epoch {epoch}: ', end='')\n",
        "        for images, labels in train_loader:\n",
        "            with tf.GradientTape() as tape:\n",
        "                images = tf.convert_to_tensor(images.numpy())\n",
        "                labels = tf.convert_to_tensor(labels.numpy())\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Evaluation\n",
        "    AUC_set = [compute_auc_takd(model, tf.convert_to_tensor(images.numpy()), tf.convert_to_tensor(labels.numpy()))\n",
        "               for images, labels in test_loader]\n",
        "    test_AUC = sum(AUC_set) / len(AUC_set) * 100\n",
        "    print(f'\\nTest AUC: {test_AUC:.2f}')\n",
        "\n",
        "    return test_AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dduQFrcYLXZa"
      },
      "outputs": [],
      "source": [
        "print('Start training teacher model')\n",
        "test_acc_teacher = train_and_evaluate_takd(teacher_model_takd, compute_teacher_loss_takd, 1e-4, train_loader_takd, test_loader_takd)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwb03bcIwfLl"
      },
      "outputs": [],
      "source": [
        "print('Start training TA model')\n",
        "test_acc_ta = train_and_evaluate_takd(ta_model_takd, compute_ta_loss_takd,1e-3,train_loader_takd, test_loader_takd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVh7HFs7gGEU"
      },
      "outputs": [],
      "source": [
        "print('Start training student model')\n",
        "test_acc_student = train_and_evaluate_takd(student_model_takd, compute_student_loss_takd, 1e-3, train_loader_takd, test_loader_takd)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Student Model = MobileNetV2\n",
        "mobilenet_model_takd_2 = MobileNetV2(include_top=True, weights='imagenet', input_shape=IMAGE_SIZE)\n",
        "for layer in mobilenet_model_takd.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_student = Dense(NUM_CLASSES, activation=None)(mobilenet_model_takd_2.output)\n",
        "last_student.trainable = True\n",
        "\n",
        "student_model_takd_2 = Model(inputs=mobilenet_model_takd_2.input, outputs=last_student)"
      ],
      "metadata": {
        "id": "Vyc1osSDiuPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_student_loss_takd(images, labels, lamb=0.5, T=4):\n",
        "    teacher_logits = teacher_model_takd(images, training=False)\n",
        "    student_logits = student_model_takd_2(images, training = True)\n",
        "\n",
        "    L_takd = takd_loss(student_logits, teacher_logits, T)\n",
        "    L_ce =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_logits))\n",
        "    loss = lamb * L_ce + (1 - lamb) * L_takd\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Wsov3d6ei0I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Start training student model')\n",
        "student = student_model_takd_2\n",
        "test_acc_student = train_and_evaluate_takd(student, compute_student_loss_takd, 1e-3, train_loader_takd, test_loader_takd)"
      ],
      "metadata": {
        "id": "6wnxcSgnjEBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ2JNFAjZoc6"
      },
      "source": [
        "# Without Pre-trained Parameters Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agQooWgXZnjV"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (224, 224, 3)\n",
        "resnet_model = ResNet50V2(include_top=True, weights=None, input_shape=IMAGE_SIZE)\n",
        "\n",
        "#Freeze the Pre-traine ResNet50V2 for inital epochs\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_teacher = Dense(2, activation=None)(resnet_model.output)  # raw logits for binary classification\n",
        "last_teacher.trainable = True\n",
        "\n",
        "#Create the New Teacher Model\n",
        "teacher_model_nopre = Model(inputs=resnet_model.input, outputs=last_teacher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O_Fur8cZuZS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def compute_teacher_loss_nopre(images, labels):\n",
        "    \"\"\"Compute the teacher loss for given images and labels.\n",
        "\n",
        "    Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    logits = teacher_model_nopre(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCHFEBluZwEw"
      },
      "outputs": [],
      "source": [
        "#Student Model = MobileNetV2\n",
        "mobilenet_model = MobileNetV2(include_top=True, weights=None, input_shape=IMAGE_SIZE)\n",
        "\n",
        "for layer in mobilenet_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_student = Dense(2, activation=None)(mobilenet_model.output)\n",
        "last_student.trainable = True\n",
        "\n",
        "student_model_nopre = Model(inputs=mobilenet_model.input, outputs=last_student)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHkMxiWoZzKS"
      },
      "outputs": [],
      "source": [
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4 #temperature hyperparameter\n",
        "\n",
        "\n",
        "def compute_student_loss_nopre(images, labels):\n",
        "\n",
        "    student_subclass_logits = student_model_nopre(images, training=True)\n",
        "    teacher_subclass_logits = teacher_model_nopre(images, training=False)\n",
        "    distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "    cross_entropy_loss_value = tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          labels, student_subclass_logits))\n",
        "\n",
        "    total_loss = cross_entropy_loss_value * ALPHA + (1 - ALPHA) * distillation_loss_value\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtX_CVsxZ3_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89971098-70e5-437d-f14e-dd8a7b395e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7bf8581436d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7bf8581436d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 68.75\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.74661003389666"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_and_evaluate(teacher_model_nopre, compute_teacher_loss_nopre, 1e-4, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q7VDTWnZ7An",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98057cf4-1fda-49dc-9fa1-92199bf8ad50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Start Initial Training Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: \n",
            "--- Start Fine-Tuning Epochs ---\n",
            "Epoch 1: Epoch 2: Epoch 3: Epoch 4: Epoch 5: Epoch 6: Epoch 7: Epoch 8: Epoch 9: Epoch 10: Epoch 11: Epoch 12: Epoch 13: Epoch 14: Epoch 15: Epoch 16: Epoch 17: Epoch 18: Epoch 19: Epoch 20: Epoch 21: Epoch 22: Epoch 23: Epoch 24: Epoch 25: \n",
            "Test AUC: 62.20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.19758064516129"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_and_evaluate(student_model_nopre, compute_student_loss_nopre, 1e-3, train_loader, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lgSh57aXA-0I",
        "mtQJgTcL4wzl",
        "h2ZEjU11SSGZ",
        "dNtxYlYOIRlo",
        "YV2Zklt_JVCw",
        "ZQ2JNFAjZoc6"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}