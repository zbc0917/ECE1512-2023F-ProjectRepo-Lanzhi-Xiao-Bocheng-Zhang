{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Citation:\n",
        "Rui Song, Dai Liu, Dave Zhenyu Chen, Andreas Festag, Carsten Trinitis, Martin Schulz, Alois C. Knoll:\n",
        "Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments. CoRR abs/2208.11311 (2022)\n"
      ],
      "metadata": {
        "id": "5-NtVEuG4ejd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import random\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "def distill_kip_unit(x_train_raw,\n",
        "                     y_train_raw,\n",
        "                     num_dd_epoch,\n",
        "                     seed,\n",
        "                     k,\n",
        "                     lr,\n",
        "                     threshold,\n",
        "                     target_sample_size,\n",
        "                     kernel_model,\n",
        "                     depth,\n",
        "                     width):\n",
        "\n",
        "    _, _, kernel_fn = get_kernel_fn(kernel_model, depth, width, 'ntk')\n",
        "    KERNEL_FN = jax.jit(functools.partial(kernel_fn, get='ntk'))\n",
        "\n",
        "    channel_means, channel_stds = get_normalization_data(x_train_raw)\n",
        "    x_train = normalize(x_train_raw, channel_means, channel_stds)\n",
        "    y_train = one_hot(y_train_raw, 10)\n",
        "\n",
        "    _, _, x_init_raw, y_init = class_balanced_sample(k, y_train_raw, x_train_raw, y_train, seed=seed)\n",
        "    x_init = normalize(x_init_raw, channel_means, channel_stds)\n",
        "    params_init = {'x': x_init, 'y': y_init}\n",
        "\n",
        "    opt_state, get_params, update_fn = get_update_functions(params_init, KERNEL_FN, lr)\n",
        "    params = get_params(opt_state)\n",
        "\n",
        "    pbar = tqdm(range(1, num_dd_epoch + 1))\n",
        "    for i in pbar:\n",
        "        # full batch gradient descent\n",
        "        _, _, x_target_batch, y_target_batch = class_balanced_sample(target_sample_size, y_train_raw, x_train, y_train)\n",
        "        opt_state, aux = update_fn(i, opt_state, params, x_target_batch, y_target_batch)\n",
        "        train_loss, train_acc = aux\n",
        "        params = get_params(opt_state)\n",
        "        pbar.set_description('Step: %d ' % i + '|Train Loss: %.4f ' % train_loss + '|Train Acc: %.4f ' % train_acc)\n",
        "\n",
        "        if train_acc > threshold:\n",
        "            print(\"converge at loop \", i)\n",
        "            break\n",
        "\n",
        "    return params\n",
        "\n",
        "class FedClient(object):\n",
        "\n",
        "    def __init__(self, client_id, dataset_id='MNIST'):\n",
        "        \"\"\"\n",
        "        Client in the federated learning for FedD3\n",
        "        :param client_id: Id of the client\n",
        "        :param dataset_id: Dataset name for the application scenario\n",
        "        \"\"\"\n",
        "        # Metadata\n",
        "        self._id = client_id\n",
        "        self._dataset_id = dataset_id\n",
        "\n",
        "        # Following private parameters are defined by dataset.\n",
        "        self._image_length = -1\n",
        "        self._image_width = -1\n",
        "        self._image_channel = -1\n",
        "\n",
        "        if self._dataset_id == 'MNIST':\n",
        "            self._image_length = 28\n",
        "            self._image_width = 28\n",
        "            self._image_channel = 1\n",
        "\n",
        "        elif self._dataset_id == 'FashionMNIST':\n",
        "            self._image_length = 28\n",
        "            self._image_width = 28\n",
        "            self._image_channel = 1\n",
        "\n",
        "        elif self._dataset_id == 'CIFAR10':\n",
        "            self._image_length = 32\n",
        "            self._image_width = 32\n",
        "            self._image_channel = 3\n",
        "\n",
        "        elif self._dataset_id == 'CIFAR100':\n",
        "            self._image_length = 32\n",
        "            self._image_width = 32\n",
        "            self._image_channel = 3\n",
        "\n",
        "        elif self._dataset_id == 'SVHN':\n",
        "            self._image_length = 32\n",
        "            self._image_width = 32\n",
        "            self._image_channel = 3\n",
        "        else:\n",
        "            print('unexpected dataset!')\n",
        "            exit(0)\n",
        "\n",
        "        # Local dataset\n",
        "        self._train_data = None\n",
        "        self._test_data = None\n",
        "\n",
        "        # Local distilled dataset\n",
        "        self._distill_data = {'x': [], 'y': []}\n",
        "\n",
        "    def load_train(self, data):\n",
        "        \"\"\"\n",
        "        Client loads the decentralized dataset, it can be Non-IID across clients.\n",
        "        :param data: Local dataset for training.\n",
        "        \"\"\"\n",
        "        self._train_data = {}\n",
        "        self._train_data = deepcopy(data)\n",
        "\n",
        "    def load_test(self, data):\n",
        "        \"\"\"\n",
        "        Client loads the test dataset.\n",
        "        :param data: Dataset for testing.\n",
        "        \"\"\"\n",
        "        self._test_data = {}\n",
        "        self._test_data = deepcopy(data)\n",
        "\n",
        "    def kip_distill(self, k,\n",
        "                    num_train_steps=2000,\n",
        "                    seed=0,\n",
        "                    lr=4e-3,\n",
        "                    threshold=0.995,\n",
        "                    target_sample_size=5000):\n",
        "        \"\"\"\n",
        "        The client run the FedD3 with KIP-based instance.\n",
        "        More details on KIP in the paper: https://arxiv.org/abs/2011.00050\n",
        "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
        "        :param num_train_steps: Number of the decentralized distillation steps\n",
        "        :param seed: Index of the used seed\n",
        "        :param lr: Learning rate of decentralized dataset distillation\n",
        "        :param threshold: Accuracy threshold for decentralized dataset distillation, when it is exceeded, the distillation breaks out.\n",
        "        :param target_sample_size: Batch size for decentralized dataset distillation\n",
        "        :return: Distilled images from decentralized dataset in this client\n",
        "        \"\"\"\n",
        "        res = []\n",
        "        print(\"Client %s \" % self._id +\n",
        "              \"starts distilling %d \" % len(self._train_data['y']) +\n",
        "              \"data points into %s data points\" % k)\n",
        "\n",
        "        params = distill_kip_unit(\n",
        "            np.array(self._train_data['x'].squeeze(1).permute(0, 2, 3, 1)),\n",
        "            np.array(self._train_data['y'].squeeze()), num_dd_epoch=num_train_steps, seed=seed, k=k, lr=lr,\n",
        "            threshold=threshold,\n",
        "            target_sample_size=target_sample_size, kernel_model='FC', depth=4, width=1024)\n",
        "\n",
        "        for data, data_label in zip(params['x'], params['y']):\n",
        "            data = np.asarray(data).tolist()\n",
        "            label = data_label.argmax(0)\n",
        "            label = np.asarray(label).tolist()\n",
        "            k_data_point = [label, data, k]\n",
        "            res.append(k_data_point)\n",
        "            self._distill_data['y'].append(k_data_point[0])\n",
        "            self._distill_data['x'].append(k_data_point[1])\n",
        "\n",
        "        self._distill_data['x'] = torch.tensor(self._distill_data['x']).permute(0, 3, 1, 2)\n",
        "        self._distill_data['y'] = torch.tensor(self._distill_data['y'])\n",
        "\n",
        "        return res\n",
        "\n",
        "    @property\n",
        "    def all_select(self):\n",
        "        \"\"\"\n",
        "        The client uploads all of the original dataset\n",
        "        :return: All of the original images\n",
        "        \"\"\"\n",
        "        return self._train_data\n",
        "\n",
        "    def herding_gmm(self, k, num_local_class, i_seed):\n",
        "        \"\"\"\n",
        "        The client run the FedD3 with coreset-based instance.\n",
        "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
        "        :param num_local_class: Number of the local classes\n",
        "        :param i_seed: Index of the used seed\n",
        "        :return: Distilled images from decentralized dataset in this client\n",
        "        \"\"\"\n",
        "        torch.manual_seed(i_seed)\n",
        "        random.seed(i_seed)\n",
        "        np.random.seed(i_seed)\n",
        "        res = []\n",
        "        self._train_data['y'] = self._train_data['y'].squeeze()\n",
        "        self._train_data['x'] = self._train_data['x'].squeeze()\n",
        "        num_datapoint = int(k / num_local_class)\n",
        "        cls_set = set()\n",
        "        for cls in self._train_data['y']:\n",
        "            cls_set.add(cls.item())\n",
        "\n",
        "        for cls in cls_set:\n",
        "            sub_data = []\n",
        "            indexes = torch.nonzero(self._train_data['y'] == cls)\n",
        "            indexes = indexes[torch.randperm(indexes.shape[0])]\n",
        "            for index in indexes:\n",
        "                sub_data.append(self._train_data['x'][index].numpy().reshape(-1).tolist())\n",
        "\n",
        "            gm = GaussianMixture(n_components=int(k / num_local_class), random_state=0).fit(sub_data)\n",
        "            for x_data in gm.means_:\n",
        "                k_data_point = [cls, np.array(x_data).reshape(1, 28, 28), k]\n",
        "                res.append(k_data_point)\n",
        "\n",
        "        return res\n",
        "\n",
        "    def dbscan(self, k, num_local_class, i_seed):\n",
        "        \"\"\"\n",
        "        The client run the FedD3 with DBSCAN-based instance.\n",
        "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
        "        :param num_local_class: Number of the local classes\n",
        "        :param i_seed: Index of the used seed\n",
        "        :return: Distilled images from decentralized dataset in this client\n",
        "        \"\"\"\n",
        "        torch.manual_seed(i_seed)\n",
        "        random.seed(i_seed)\n",
        "        np.random.seed(i_seed)\n",
        "        res = []\n",
        "        self._train_data['y'] = self._train_data['y'].squeeze()\n",
        "        self._train_data['x'] = self._train_data['x'].squeeze()\n",
        "        num_datapoint = int(k / num_local_class)\n",
        "        cls_set = set()\n",
        "        for cls in self._train_data['y']:\n",
        "            cls_set.add(cls.item())\n",
        "\n",
        "        for cls in cls_set:\n",
        "            sub_data = []\n",
        "            indexes = torch.nonzero(self._train_data['y'] == cls)\n",
        "            indexes = indexes[torch.randperm(indexes.shape[0])]\n",
        "            for index in indexes:\n",
        "                sub_data.append(self._train_data['x'][index].numpy().reshape(-1).tolist())\n",
        "            db = DBSCAN(eps=40.5, min_samples=2).fit(sub_data)\n",
        "            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "            core_samples_mask[db.core_sample_indices_] = True\n",
        "            labels = db.labels_\n",
        "\n",
        "            # Number of clusters in labels, ignoring noise if present.\n",
        "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "            print(n_clusters_)\n",
        "            n_noise_ = list(labels).count(-1)\n",
        "            unique_labels = set(labels)\n",
        "            cluster_centers_ = []\n",
        "            for k in unique_labels:\n",
        "                # discard the unclustered points\n",
        "                if k == -1:\n",
        "                    continue\n",
        "                class_member_mask = (labels == k)\n",
        "                cluster = np.array(sub_data)[class_member_mask & core_samples_mask]\n",
        "                cluster_centers_.append(np.mean(cluster, axis=0))\n",
        "\n",
        "            for x_data in cluster_centers_:\n",
        "                k_data_point = [cls, np.array(x_data).reshape(3, 32, 32), k]\n",
        "                res.append(k_data_point)\n",
        "\n",
        "        return res\n",
        "\n",
        "    def save_distilled_dataset(self, exp_dir='client_models', res_root='results'):\n",
        "        \"\"\"\n",
        "        The client saves the distilled images in corresponding directory\n",
        "        :param exp_dir: Experiment directory name\n",
        "        :param res_root: Result directory root for saving the result files\n",
        "        \"\"\"\n",
        "        agent_name = 'clients'\n",
        "        model_save_dir = os.path.join(res_root, exp_dir, agent_name)\n",
        "        if not os.path.exists(model_save_dir):\n",
        "            os.makedirs(model_save_dir)\n",
        "        torch.save(self._distill_data, os.path.join(model_save_dir, self._id + '_distilled_img.pt'))"
      ],
      "metadata": {
        "id": "InsO2bT7jhPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "\"\"\"\n",
        "We provide the models, which might be used in the experiments on FedD3, as follows:\n",
        "    - AlexNet model customized for CIFAR-10 (AlexCifarNet) with 1756426 parameters\n",
        "    - LeNet model customized for MNIST with 61706 parameters\n",
        "    - Further ResNet models\n",
        "    - Further Vgg models\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# AlexNet model customized for CIFAR-10 with 1756426 parameters\n",
        "class AlexCifarNet(nn.Module):\n",
        "    supported_dims = {32}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AlexCifarNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.LocalResponseNorm(4, alpha=0.001 / 9.0, beta=0.75, k=1),\n",
        "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(4, alpha=0.001 / 9.0, beta=0.75, k=1),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(4096, 384),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(384, 192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(192, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), 4096)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# LeNet model customized for MNIST with 61706 parameters\n",
        "class LeNet(nn.Module):\n",
        "    supported_dims = {28}\n",
        "\n",
        "    def __init__(self, num_classes=10, in_channels=1):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x), inplace=True)  # 6 x 28 x 28\n",
        "        out = F.max_pool2d(out, 2)  # 6 x 14 x 14\n",
        "        out = F.relu(self.conv2(out), inplace=True)  # 16 x 7 x 7\n",
        "        out = F.max_pool2d(out, 2)   # 16 x 5 x 5\n",
        "        out = out.view(out.size(0), -1)  # 16 x 5 x 5\n",
        "        out = F.relu(self.fc1(out), inplace=True)\n",
        "        out = F.relu(self.fc2(out), inplace=True)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# Further ResNet models\n",
        "def generate_resnet(num_classes=10, in_channels=1, model_name=\"ResNet18\"):\n",
        "    if model_name == \"ResNet18\":\n",
        "        model = models.resnet18(pretrained=True)\n",
        "    elif model_name == \"ResNet34\":\n",
        "        model = models.resnet34(pretrained=True)\n",
        "    elif model_name == \"ResNet50\":\n",
        "        model = models.resnet50(pretrained=True)\n",
        "    elif model_name == \"ResNet101\":\n",
        "        model = models.resnet101(pretrained=True)\n",
        "    elif model_name == \"ResNet152\":\n",
        "        model = models.resnet152(pretrained=True)\n",
        "    model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    fc_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(fc_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Further Vgg models\n",
        "def generate_vgg(num_classes=10, in_channels=1, model_name=\"vgg11\"):\n",
        "    if model_name == \"VGG11\":\n",
        "        model = models.vgg11(pretrained=False)\n",
        "    elif model_name == \"VGG11_bn\":\n",
        "        model = models.vgg11_bn(pretrained=True)\n",
        "    elif model_name == \"VGG13\":\n",
        "        model = models.vgg11(pretrained=False)\n",
        "    elif model_name == \"VGG13_bn\":\n",
        "        model = models.vgg11_bn(pretrained=True)\n",
        "    elif model_name == \"VGG16\":\n",
        "        model = models.vgg11(pretrained=False)\n",
        "    elif model_name == \"VGG16_bn\":\n",
        "        model = models.vgg11_bn(pretrained=True)\n",
        "    elif model_name == \"VGG19\":\n",
        "        model = models.vgg11(pretrained=False)\n",
        "    elif model_name == \"VGG19_bn\":\n",
        "        model = models.vgg11_bn(pretrained=True)\n",
        "\n",
        "    # first_conv_layer = [nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=True)]\n",
        "    # first_conv_layer.extend(list(model.features))\n",
        "    # model.features = nn.Sequential(*first_conv_layer)\n",
        "    # model.conv1 = nn.Conv2d(num_classes, 64, 7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    fc_features = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(fc_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, in_channels=1):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.fp_con1 = nn.Sequential(OrderedDict([\n",
        "            ('con0', nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ]))\n",
        "\n",
        "        self.ternary_con2 = nn.Sequential(OrderedDict([\n",
        "            # Conv Layer block 1\n",
        "            ('conv1', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, bias=False)),\n",
        "            ('norm1', nn.BatchNorm2d(64)),\n",
        "            ('relu1', nn.ReLU(inplace=True)),\n",
        "            ('pool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            ('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, bias=False)),\n",
        "            ('norm2', nn.BatchNorm2d(128)),\n",
        "            ('relu2', nn.ReLU(inplace=True)),\n",
        "            ('conv3', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=False)),\n",
        "            ('norm3', nn.BatchNorm2d(128)),\n",
        "            ('relu3', nn.ReLU(inplace=True)),\n",
        "            ('pool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
        "            # nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            ('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, bias=False)),\n",
        "            ('norm3', nn.BatchNorm2d(256)),\n",
        "            ('relu3', nn.ReLU(inplace=True)),\n",
        "            ('conv4', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=False)),\n",
        "            ('norm4', nn.BatchNorm2d(256)),\n",
        "            ('relu4', nn.ReLU(inplace=True)),\n",
        "            ('pool4', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
        "        ]))\n",
        "\n",
        "        self.fp_fc = nn.Linear(4096, num_classes, bias = False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fp_con1(x)\n",
        "        x = self.ternary_con2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fp_fc(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_name_list = [\"ResNet18\", \"ResNet34\", \"ResNet50\", \"ResNet101\", \"ResNet152\"]\n",
        "    for model_name in model_name_list:\n",
        "        model = generate_resnet(num_classes=10, in_channels=1, model_name=model_name)\n",
        "        model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "        param_len = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        print('Number of model parameters of %s :' % model_name, ' %d ' % param_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjIYh8CwkJwb",
        "outputId": "a6ddae24-b153-4cce-b0cd-8969266e54e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 173MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of ResNet18 :  11175370 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 72.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of ResNet34 :  21283530 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 70.4MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of ResNet50 :  23522250 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:00<00:00, 197MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of ResNet101 :  42514378 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:03<00:00, 75.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of ResNet152 :  58158026 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from json import JSONEncoder\n",
        "import pickle\n",
        "\n",
        "json_types = (list, dict, str, int, float, bool, type(None))\n",
        "\n",
        "class Recorder(object):\n",
        "    def __init__(self):\n",
        "        self.res_list = []\n",
        "        self.res = {'server': {'iid_accuracy': [], 'train_loss': []},\n",
        "                    'clients': {'iid_accuracy': [], 'train_loss': []}}\n",
        "\n",
        "    def load(self, filename, label):\n",
        "        \"\"\"\n",
        "        Load the result files\n",
        "        :param filename: Name of the result file\n",
        "        :param label: Label for the result file\n",
        "        \"\"\"\n",
        "        with open(filename) as json_file:\n",
        "            res = json.load(json_file, object_hook=as_python_object)\n",
        "        self.res_list.append((res, label))\n",
        "\n",
        "    def plot(self):\n",
        "        \"\"\"\n",
        "        Plot the testing accuracy and training loss on number of epochs or communication rounds\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2)\n",
        "        for i, (res, label) in enumerate(self.res_list):\n",
        "            axes[0].plot(np.array(res['server']['iid_accuracy']), label=label, alpha=1, linewidth=2)\n",
        "            axes[1].plot(np.array(res['server']['train_loss']), label=label, alpha=1, linewidth=2)\n",
        "\n",
        "        for i, ax in enumerate(axes):\n",
        "            ax.set_xlabel('# of Epochs', size=12)\n",
        "            if i == 0:\n",
        "                ax.set_ylabel('Testing Accuracy', size=12)\n",
        "            if i == 1:\n",
        "                ax.set_ylabel('Training Loss', size=12)\n",
        "            ax.legend(prop={'size': 12})\n",
        "            ax.tick_params(axis='both', labelsize=12)\n",
        "            ax.grid()"
      ],
      "metadata": {
        "id": "UY9Ysx1ekh-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from json import JSONEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "class PythonObjectEncoder(JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, json_types):\n",
        "            return super().default(self, obj)\n",
        "        return {'_python_object': pickle.dumps(obj).decode('latin-1')}\n",
        "\n",
        "\n",
        "def as_python_object(dct):\n",
        "    if '_python_object' in dct:\n",
        "        return pickle.loads(dct['_python_object'].encode('latin-1'))\n",
        "    return dct\n",
        "\n",
        "\n",
        "json_types = (list, dict, str, int, float, bool, type(None))\n",
        "class FedServer(object):\n",
        "    def __init__(self, epoch, batch_size, lr, momentum, num_workers, dataset_id='mnist', server_id='server', model_name=\"LeNet\", i_seed=0, test_on_gpu=True):\n",
        "        \"\"\"\n",
        "        Server in the federated learning for FedD3\n",
        "        :param epoch: Number of total training epochs in the server\n",
        "        :param batch_size: Batch size for the training in the server\n",
        "        :param lr: Learning rate for the training in the server\n",
        "        :param momentum: Learning momentum for the training in the server\n",
        "        :param num_workers: Number of the workers for the training in the server\n",
        "        :param dataset_id: Dataset name for the application scenario\n",
        "        :param server_id: Id of the server\n",
        "        :param model_name: Machine learning model name for the application scenario\n",
        "        :param i_seed: Index of the seed used in the experiment\n",
        "        :param test_on_gpu: Flag: 1: Run testing on GPU after every epoch, otherwise 0.\n",
        "        \"\"\"\n",
        "        data_dict = ['MNIST', 'FashionMNIST', 'CIFAR10', 'SVHN', 'CIFAR100']\n",
        "        assert dataset_id in data_dict, \"The dataset is not present\"\n",
        "\n",
        "        self.test_on_gpu = test_on_gpu\n",
        "\n",
        "        # Server Properties\n",
        "        self._id = server_id\n",
        "        self._dataset_id = dataset_id\n",
        "        self._model_name = model_name\n",
        "        self._i_seed = i_seed\n",
        "\n",
        "        # Training related parameters\n",
        "        self._epoch = epoch\n",
        "        self._batch_size = batch_size\n",
        "        self._lr = lr\n",
        "        self._momentum = momentum\n",
        "        self._num_workers = num_workers\n",
        "\n",
        "        # Global test dataset\n",
        "        self._test_data = None\n",
        "\n",
        "        # Global distilled dataset\n",
        "        self._distill_data = None\n",
        "\n",
        "        # Following private parameters are defined by dataset.\n",
        "        self.model = None\n",
        "        self._image_dim = -1\n",
        "        self._image_channel = -1\n",
        "\n",
        "        if self._dataset_id == 'MNIST':\n",
        "            self._num_class = 10\n",
        "            self._image_dim = 28\n",
        "            self._image_channel = 1\n",
        "\n",
        "        if self._dataset_id == 'FashionMNIST':\n",
        "            self._num_class = 10\n",
        "            self._image_dim = 28\n",
        "            self._image_channel = 1\n",
        "\n",
        "        elif self._dataset_id == 'SVHN':\n",
        "            self._num_class = 10\n",
        "            self._image_dim = 32\n",
        "            self._image_channel = 3\n",
        "\n",
        "        elif self._dataset_id == 'EMNIST':\n",
        "            self._num_class = 27\n",
        "            self._image_dim = 28\n",
        "            self._image_channel = 1\n",
        "\n",
        "        elif self._dataset_id == 'CIFAR10':\n",
        "            self._num_class = 10\n",
        "            self._image_dim = 32\n",
        "            self._image_channel = 3\n",
        "\n",
        "        elif self._dataset_id == 'CIFAR100':\n",
        "            self._num_class = 100\n",
        "            self._image_dim = 32\n",
        "            self._image_channel = 3\n",
        "\n",
        "        if self._model_name == \"ResNet18\":\n",
        "            self.model = generate_resnet(num_classes=self._num_class, in_channels=self._image_channel ,model_name=model_name)\n",
        "        elif self._model_name == \"ResNet50\":\n",
        "            self.model = generate_resnet(num_classes=self._num_class, in_channels=self._image_channel ,model_name=model_name)\n",
        "        elif self._model_name == \"ResNet152\":\n",
        "            self.model = generate_resnet(num_classes=self._num_class, in_channels=self._image_channel, model_name=model_name)\n",
        "        elif self._model_name == \"LeNet\":\n",
        "            self.model = LeNet(self._num_class, self._image_channel)\n",
        "        elif self._model_name == \"VGG11\":\n",
        "            self.model = generate_vgg(self._num_class, self._image_channel, model_name=model_name)\n",
        "        elif self._model_name == \"VGG11_bn\":\n",
        "            self.model = generate_vgg(self._num_class, self._image_channel, model_name=model_name)\n",
        "        elif self._model_name == \"AlexCifarNet\":\n",
        "            self.model = AlexCifarNet()\n",
        "        elif self._model_name == \"CNN\":\n",
        "            self.model = CNN(self._num_class, self._image_channel)\n",
        "        else:\n",
        "            print('Model is not supported')\n",
        "\n",
        "        # Number of model parameter\n",
        "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.param_len = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        print('Number of model parameters of %s :' % model_name, ' %d ' % self.param_len)\n",
        "        # Recording results\n",
        "        self.recorder = Recorder()\n",
        "        # Run on the GPU\n",
        "        gpu = 0\n",
        "        self._device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
        "\n",
        "    def load_test(self, data):\n",
        "        \"\"\"\n",
        "        Server loads the test dataset.\n",
        "        :param data: Dataset for testing.\n",
        "        \"\"\"\n",
        "        self._test_data = {}\n",
        "        self._test_data = deepcopy(data)\n",
        "\n",
        "    def load_distill(self, data):\n",
        "        \"\"\"\n",
        "        Server loads the decentralized distilled dataset.\n",
        "        :param data: Dataset for training.\n",
        "        \"\"\"\n",
        "        self._distill_data = {}\n",
        "        self._distill_data = deepcopy(data)\n",
        "\n",
        "    def train(self, exp_dir, res_root='results', i_seed=0):\n",
        "        \"\"\"\n",
        "        Server trains models on the decentralized distilled datasets from networks\n",
        "        :param exp_dir: Experiment directory name\n",
        "        :param res_root: Result directory root for saving the result files\n",
        "        :param i_seed: Index of the used seed\n",
        "        :return: Loss in the training.\n",
        "        \"\"\"\n",
        "        torch.manual_seed(i_seed)\n",
        "        np.random.seed(i_seed)\n",
        "        state_dict_list = []\n",
        "\n",
        "        # Create the train and test loader\n",
        "        with torch.no_grad():\n",
        "\n",
        "            train_x = self._distill_data['x'].type(torch.FloatTensor).squeeze()\n",
        "            if len(train_x.shape) == 3:\n",
        "                train_x = train_x.unsqueeze(1)\n",
        "            train_y = self._distill_data['y'].type(torch.LongTensor).squeeze()\n",
        "\n",
        "            test_x = self._test_data['x'].type(torch.FloatTensor).squeeze()\n",
        "            if len(test_x.shape) == 3:\n",
        "                test_x = test_x.unsqueeze(1)\n",
        "            test_y = self._test_data['y'].type(torch.FloatTensor).squeeze()\n",
        "\n",
        "            train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=self._batch_size, shuffle=True)\n",
        "            test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=self._batch_size, shuffle=True)\n",
        "\n",
        "            self.model.to(self._device)\n",
        "            # optimizer = torch.optim.SGD(self.model.parameters(), lr=self._lr, momentum=self._momentum)\n",
        "            optimizer = torch.optim.Adam(self.model.parameters(), lr=self._lr, weight_decay=1e-4)\n",
        "            loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Train process\n",
        "        pbar = tqdm(range(self._epoch))\n",
        "        for epoch in pbar:\n",
        "            for step, (x, y) in enumerate(train_loader):\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    b_x = x.to(self._device)  # Tensor on GPU\n",
        "                    b_y = y.to(self._device)  # Tensor on GPU\n",
        "\n",
        "                with torch.enable_grad():\n",
        "                    self.model.train()\n",
        "                    output = self.model(b_x)\n",
        "                    loss = loss_func(output, b_y)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # Recording the train loss during the training\n",
        "            self.recorder.res['server']['train_loss'].append(loss.data.cpu().numpy())\n",
        "\n",
        "            # Test process\n",
        "            if self.test_on_gpu:\n",
        "                accuracy_collector = 0\n",
        "                for step, (x, y) in enumerate(test_loader):\n",
        "                    with torch.no_grad():\n",
        "                        b_x = x.to(self._device)  # Tensor on GPU\n",
        "                        b_y = y.to(self._device)  # Tensor on GPU\n",
        "                        test_output = self.model(b_x)\n",
        "                        pred_y = torch.max(test_output, 1)[1].to(self._device).data.squeeze()\n",
        "                        accuracy_collector = accuracy_collector + sum(pred_y == b_y)\n",
        "                accuracy = accuracy_collector / self._test_data['y'].size(0)\n",
        "                self.recorder.res['server']['iid_accuracy'].append(accuracy.cpu().numpy())\n",
        "\n",
        "                pbar.set_description('Epoch: %d' % epoch +\n",
        "                                     '| Train loss: %.4f ' % loss.data.cpu().numpy() +\n",
        "                                     '| Accuracy: %.4f' % accuracy +\n",
        "                                     '| Max Acc: %.4f' % np.max(np.array(self.recorder.res['server']['iid_accuracy'])))\n",
        "            else:\n",
        "                pbar.set_description('Epoch: %d', epoch + '| Train loss: %.4f ' % loss.data.cpu().numpy())\n",
        "            state_dict_list.append(self.model.state_dict())\n",
        "\n",
        "        # Save the results\n",
        "        if not os.path.exists(res_root):\n",
        "            os.makedirs(res_root)\n",
        "\n",
        "        with open(os.path.join(res_root, exp_dir), \"w\") as jsfile:\n",
        "            json.dump(self.recorder.res, jsfile, cls=PythonObjectEncoder)\n",
        "\n",
        "        return loss.data.cpu().numpy()"
      ],
      "metadata": {
        "id": "1A4Gshs3j3wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "def load_data(name, root='./data', download=True, save_pre_data=True):\n",
        "\n",
        "    data_dict = ['MNIST', 'EMNIST', 'FashionMNIST', 'CelebA', 'CIFAR10', 'QMNIST', 'SVHN', 'CIFAR100']\n",
        "    assert name in data_dict, \"The dataset is not present\"\n",
        "\n",
        "    if not os.path.exists(root):\n",
        "        os.makedirs(root, exist_ok=True)\n",
        "\n",
        "    file_dir = root+'/prepared/'\n",
        "    test_data_file = file_dir + name + '_test.pt'\n",
        "    train_data_file = file_dir + name + '_train.pt'\n",
        "    test_targets_file = file_dir + name + '_test_label.pt'\n",
        "    train_targets_file = file_dir + name + '_train_label.pt'\n",
        "\n",
        "    if not os.path.exists(file_dir):\n",
        "        os.makedirs(file_dir, exist_ok=True)\n",
        "\n",
        "    all_file_there = os.path.exists(train_data_file) and os.path.exists(test_data_file) and os.path.exists(train_targets_file) and os.path.exists(test_targets_file)\n",
        "\n",
        "    if save_pre_data or not all_file_there:\n",
        "\n",
        "        if name == 'MNIST':\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "            trainset = torchvision.datasets.MNIST(root=root, train=True, download=download, transform=transform)\n",
        "            testset = torchvision.datasets.MNIST(root=root, train=False, download=download, transform=transform)\n",
        "\n",
        "        elif name == 'EMNIST':\n",
        "            # byclass, bymerge, balanced, letters, digits, mnist\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "            trainset = torchvision.datasets.EMNIST(root=root, train=True, split= 'letters', download=download, transform=transform)\n",
        "            testset = torchvision.datasets.EMNIST(root=root, train=False, split= 'letters', download=download, transform=transform)\n",
        "\n",
        "        elif name == 'FashionMNIST':\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "            trainset = torchvision.datasets.FashionMNIST(root=root, train=True, download=download, transform=transform)\n",
        "            testset = torchvision.datasets.FashionMNIST(root=root, train=False, download=download, transform=transform)\n",
        "\n",
        "        elif name == 'CelebA':\n",
        "            # Could not loaded possibly for google drive break downs, try again at week days\n",
        "            target_transform = transforms.Compose([transforms.ToTensor()])\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "            trainset = torchvision.datasets.CelebA(root=root, split='train', target_type=list, download=download, transform=transform, target_transform=target_transform)\n",
        "            testset = torchvision.datasets.CelebA(root=root, split='test', target_type=list, download=download, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        elif name == 'CIFAR10':\n",
        "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
        "            trainset = torchvision.datasets.CIFAR10(root=root, train=True, download=download, transform=transform)\n",
        "            testset = torchvision.datasets.CIFAR10(root=root, train=False, download=download, transform=transform)\n",
        "            trainset.targets = torch.Tensor(trainset.targets)\n",
        "            testset.targets = torch.Tensor(testset.targets)\n",
        "\n",
        "        elif name == 'CIFAR100':\n",
        "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "            trainset = torchvision.datasets.CIFAR100(root=root, train=True, transform=transform, download=True)\n",
        "            testset = torchvision.datasets.CIFAR100(root=root, train=False, transform=transform, download=True)\n",
        "            trainset.targets = torch.Tensor(trainset.targets)\n",
        "            testset.targets = torch.Tensor(testset.targets)\n",
        "\n",
        "        elif name == 'QMNIST':\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "            trainset = torchvision.datasets.QMNIST(root=root, what='train', compat=True, download=download, transform=transform)\n",
        "            testset = torchvision.datasets.QMNIST(root=root, what='test', compat=True, download=download, transform=transform)\n",
        "\n",
        "        elif name == 'SVHN':\n",
        "\n",
        "            transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))])\n",
        "            trainset = torchvision.datasets.SVHN(root=root, split='train', download=download, transform=transform)\n",
        "            testset = torchvision.datasets.SVHN(root=root, split='test', download=download, transform=transform)\n",
        "            trainset.targets = torch.Tensor(trainset.labels)\n",
        "            testset.targets = torch.Tensor(testset.labels)\n",
        "\n",
        "        end = len(trainset)-1\n",
        "        copy_burden = 50\n",
        "        for i,x in tqdm(enumerate(trainset)):\n",
        "            if i == end:\n",
        "                temp = torch.cat((temp, torch.unsqueeze(x[0],0)))\n",
        "                train_data = torch.cat((train_data, temp))\n",
        "                train_targets = trainset.targets\n",
        "\n",
        "            elif i%copy_burden != 0:\n",
        "                temp = torch.cat((temp, torch.unsqueeze(x[0],0)))\n",
        "\n",
        "            elif i/copy_burden != 0 and i/copy_burden != 1:\n",
        "                train_data = torch.cat((train_data, temp))\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "            elif i/copy_burden == 0:\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "            else:\n",
        "                train_data = temp\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "        end = len(testset)-1\n",
        "        for i,x in tqdm(enumerate(testset)):\n",
        "            if i == end:\n",
        "                temp = torch.cat((temp, torch.unsqueeze(x[0],0)))\n",
        "                test_data = torch.cat((test_data, temp))\n",
        "                test_targets = testset.targets\n",
        "\n",
        "            elif i%copy_burden != 0:\n",
        "                temp = torch.cat((temp, torch.unsqueeze(x[0],0)))\n",
        "\n",
        "            elif i/copy_burden != 0 and i/copy_burden != 1:\n",
        "                test_data = torch.cat((test_data, temp))\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "            elif i/copy_burden == 0:\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "            else:\n",
        "                test_data = temp\n",
        "                temp = torch.unsqueeze(x[0], 0)\n",
        "\n",
        "        torch.save(train_data, train_data_file)\n",
        "        torch.save(test_data, test_data_file)\n",
        "        torch.save(train_targets, train_targets_file)\n",
        "        torch.save(test_targets, test_targets_file)\n",
        "\n",
        "    elif all_file_there and not save_pre_data:\n",
        "        train_data = torch.load(train_data_file)\n",
        "        test_data = torch.load(test_data_file)\n",
        "        train_targets = torch.load(train_targets_file)\n",
        "        test_targets = torch.load(test_targets_file)\n",
        "\n",
        "    # Set len_classes\n",
        "    len_classes_dict = {\n",
        "        'MNIST': 10,\n",
        "        'EMNIST': 27, # ByClass: 62. ByMerge: 814,255 47.Digits: 280,000 10.Letters: 145,600 26.MNIST: 70,000 10.\n",
        "        'FashionMNIST': 10,\n",
        "        'CelebA': 0,\n",
        "        'CIFAR10': 10,\n",
        "        'CIFAR100': 100,\n",
        "        'QMNIST': 10,\n",
        "        'SVHN': 10\n",
        "    }\n",
        "\n",
        "    len_classes = len_classes_dict[name]\n",
        "\n",
        "    return len_classes, train_data, train_targets, test_data, test_targets\n",
        "\n",
        "\n",
        "def divide_data(num_client=1, num_local_class=10, dataset_name='emnist', i_seed=0):\n",
        "    torch.manual_seed(i_seed)\n",
        "\n",
        "    num_classes, train_data, train_targets, test_data, test_targets = load_data(dataset_name, download=True, save_pre_data=False)\n",
        "\n",
        "    # import pdb; pdb.set_trace()\n",
        "    if num_local_class == -1:\n",
        "        num_local_class = num_classes\n",
        "    assert 0 < num_local_class <= num_classes, \"number of local class should smaller than global number of class\"\n",
        "\n",
        "    trainset_config = {'users': [],\n",
        "                       'user_data': {},\n",
        "                       'num_samples': []}\n",
        "    config_division = {}  # Count of the classes for division\n",
        "    config_class = {}  # Configuration of class distribution in clients\n",
        "    config_data = {}  # Configuration of data indexes for each class : Config_data[cls] = [0, []] | pointer and indexes\n",
        "\n",
        "    for i in range(num_client):\n",
        "        config_class['f_{0:05d}'.format(i)] = []\n",
        "        for j in range(num_local_class):\n",
        "            cls = (i+j) % num_classes\n",
        "            if cls not in config_division:\n",
        "                config_division[cls] = 1\n",
        "                config_data[cls] = [0, []]\n",
        "\n",
        "            else:\n",
        "                config_division[cls] += 1\n",
        "            config_class['f_{0:05d}'.format(i)].append(cls)\n",
        "\n",
        "    for cls in config_division.keys():\n",
        "        indexes = torch.nonzero(train_targets == cls)\n",
        "        num_datapoint = indexes.shape[0]\n",
        "        indexes = indexes[torch.randperm(num_datapoint)]\n",
        "        num_partition = num_datapoint // config_division[cls]\n",
        "        for i_partition in range(config_division[cls]):\n",
        "            if i_partition == config_division[cls] - 1:\n",
        "                config_data[cls][1].append(indexes[i_partition * num_partition:])\n",
        "            else:\n",
        "                config_data[cls][1].append(indexes[i_partition * num_partition: (i_partition + 1) * num_partition])\n",
        "\n",
        "    for user in tqdm(config_class.keys()):\n",
        "        user_data_indexes = torch.tensor([])\n",
        "        for cls in config_class[user]:\n",
        "            user_data_index = config_data[cls][1][config_data[cls][0]]\n",
        "            user_data_indexes = torch.cat((user_data_indexes, user_data_index))\n",
        "            config_data[cls][0] += 1\n",
        "            # print(len(user_data_indexes))\n",
        "        user_data = train_data[user_data_indexes.tolist()]\n",
        "        user_targets = train_targets[user_data_indexes.tolist()]\n",
        "        trainset_config['users'].append(user)\n",
        "        trainset_config['user_data'][user] = {'x': user_data, 'y': user_targets}\n",
        "        trainset_config['num_samples'] = len(user_data)\n",
        "        # print(trainset_config['user_data'][user].shape)\n",
        "\n",
        "    test_iid_data = {'x': None, 'y': None}\n",
        "    test_iid_data['x'] = test_data\n",
        "    test_iid_data['y'] = test_targets\n",
        "\n",
        "    return trainset_config, test_iid_data\n"
      ],
      "metadata": {
        "id": "aTtJpdsym0eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1igJcMo1i46B",
        "outputId": "db00ea43-1525-4011-fd4c-6f8fa8636eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 253056783.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 39266027.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 145252166.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 6614766.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "60000it [00:31, 1930.82it/s]\n",
            "10000it [00:02, 4073.79it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 573.21it/s]\n",
            "<ipython-input-6-9494e22f8fed>:102: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters of LeNet :  61706 \n",
            "Server gets 500 images\n",
            "Server starts experiment with  i_seed=0 | epoch=500 | batch_size=50 | lr=0.0100 | momentum=0.9000 | num_workers=1 | dataset_id=MNIST | model_name=LeNet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 499| Train loss: 2.3032 | Accuracy: 0.0892| Max Acc: 0.7385: 100%|██████████| 500/500 [03:11<00:00,  2.62it/s]\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.sys_n_client = 50\n",
        "        self.sys_n_local_class = 10\n",
        "        self.sys_dataset = 'MNIST'\n",
        "        self.sys_model = 'LeNet'\n",
        "        self.sys_i_seed = 0\n",
        "        self.sys_res_root = 'results'\n",
        "        self.server_n_epoch = 500\n",
        "        self.server_bs = 50\n",
        "        self.server_lr = 0.01\n",
        "        self.server_momentum = 0.9\n",
        "        self.server_n_worker = 1\n",
        "        self.client_instance = 'gmm'\n",
        "        self.client_n_dd = 10\n",
        "        self.client_instance_lr = 0.004\n",
        "        self.client_instance_bs = 10\n",
        "        self.client_instance_max_n_epoch = 300\n",
        "        self.client_instance_threshold = 0.999\n",
        "\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"\n",
        "    Main function for FedD3\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    mode_list = [\"all_select\", \"kip_distill\", \"gmm\", \"dbscan\"]\n",
        "    assert args.client_instance in mode_list, \"The mode is not supported\"\n",
        "\n",
        "    dataset_list = ['MNIST', 'CIFAR10', 'FashionMNIST', 'SVHN', 'CIFAR100']\n",
        "    assert args.sys_dataset in dataset_list, \"The dataset is not supported\"\n",
        "\n",
        "    model_list = [\"LeNet\", 'AlexCifarNet', 'CNN', 'ResNet18', 'ResNet50', \"ResNet152\"]\n",
        "    assert args.sys_model in model_list, \"The model is not supported\"\n",
        "\n",
        "    # Number of all distilled data points\n",
        "    num_images = int(args.client_n_dd * args.sys_n_client)\n",
        "\n",
        "    # Set the experiment name with hyperparameters\n",
        "    exp_name = '[\"%s\",\"%s\",%d,%d,%d,%d]' % (\n",
        "        args.sys_dataset, args.sys_model, num_images, args.client_n_dd, args.sys_n_client, args.sys_n_local_class)\n",
        "\n",
        "    if args.client_instance == \"all_select\":\n",
        "        args.sys_n_client = 1\n",
        "        args.sys_n_local_class = -1\n",
        "\n",
        "    torch.manual_seed(args.sys_i_seed)\n",
        "    random.seed(args.sys_i_seed)\n",
        "    np.random.seed(args.sys_i_seed)\n",
        "\n",
        "    client_dict = {}\n",
        "    distill_dataset = {'x': [], 'y': []}\n",
        "\n",
        "    # Distribute the dataset into each client with respect to number of local classes\n",
        "    trainset_config, test_iid_data = divide_data(num_client=args.sys_n_client,\n",
        "                                                 num_local_class=args.sys_n_local_class,\n",
        "                                                 dataset_name=args.sys_dataset,\n",
        "                                                 i_seed=args.sys_i_seed)\n",
        "\n",
        "    # Initialize each client and distill the local data.\n",
        "    # (Since it is one-shot, initialization does not have to do separately)\n",
        "    for client_id in trainset_config['users']:\n",
        "        client_dict[client_id] = FedClient(client_id, dataset_id=args.sys_dataset)\n",
        "        client_dict[client_id].load_train(trainset_config['user_data'][client_id])\n",
        "\n",
        "        ret_data = []\n",
        "        if args.client_instance == \"all_select\":\n",
        "            distill_dataset = client_dict[client_id].all_select\n",
        "        elif args.client_instance == \"gmm\":\n",
        "            ret_data = client_dict[client_id].herding_gmm(k=args.client_n_dd, num_local_class=args.sys_n_local_class, i_seed=args.sys_i_seed)\n",
        "        elif args.client_instance == \"dbscan\":\n",
        "            ret_data = client_dict[client_id].dbscan(k=args.client_n_dd, num_local_class=args.sys_n_local_class, i_seed=args.sys_i_seed)\n",
        "        elif args.client_instance == \"kip_distill\":\n",
        "            ret_data = client_dict[client_id].kip_distill(\n",
        "                args.client_n_dd,\n",
        "                num_train_steps=args.client_instance_max_n_epoch,\n",
        "                seed=args.sys_i_seed,\n",
        "                lr=args.client_instance_lr,\n",
        "                threshold=args.client_instance_threshold,\n",
        "                target_sample_size=args.client_instance_bs)\n",
        "        for k_data_point in ret_data:\n",
        "            distill_dataset['y'].append(k_data_point[0])\n",
        "            distill_dataset['x'].append(k_data_point[1])\n",
        "\n",
        "    if args.client_instance == \"all_select\":\n",
        "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
        "        distill_dataset['x'] = distill_dataset['x'].squeeze()\n",
        "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
        "    elif args.client_instance == \"gmm\":\n",
        "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
        "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
        "    elif args.client_instance == \"dbscan\":\n",
        "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
        "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
        "    elif args.client_instance == \"kip_distill\":\n",
        "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
        "        distill_dataset['x'] = distill_dataset['x'].permute(0, 3, 1, 2)\n",
        "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
        "\n",
        "    # Initialize the server in federated learning\n",
        "    server = FedServer(epoch=args.server_n_epoch,\n",
        "                       batch_size=args.server_bs,\n",
        "                       lr=args.server_lr, momentum=args.server_momentum,\n",
        "                       num_workers=args.server_n_worker,\n",
        "                       server_id='server',\n",
        "                       dataset_id=args.sys_dataset,\n",
        "                       model_name=args.sys_model,\n",
        "                       i_seed=args.sys_i_seed,\n",
        "                       test_on_gpu=True)\n",
        "\n",
        "    # Server loads non-iid test dataset\n",
        "    server.load_test(test_iid_data)\n",
        "    # Server collects the decentralized distilled dataset from clients\n",
        "    server.load_distill(distill_dataset)\n",
        "    print('Server gets %d images' % len(distill_dataset['y']))\n",
        "    print('Server starts experiment with  '\n",
        "          'i_seed=%d' % args.sys_i_seed,\n",
        "          '| epoch=%d' % args.server_n_epoch,\n",
        "          '| batch_size=%d' % args.server_bs,\n",
        "          '| lr=%.4f' % args.server_lr,\n",
        "          '| momentum=%.4f' % args.server_momentum,\n",
        "          '| num_workers=%d' % args.server_n_worker,\n",
        "          '| dataset_id=%s' % args.sys_dataset,\n",
        "          '| model_name=%s' % args.sys_model)\n",
        "    # Server trains models\n",
        "    server.train(exp_name, args.sys_res_root)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = Args()\n",
        "    main(args)"
      ]
    }
  ]
}