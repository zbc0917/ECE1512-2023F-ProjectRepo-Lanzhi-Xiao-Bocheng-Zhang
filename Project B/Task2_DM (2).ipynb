{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Citation:\n",
        "@article{song2022federated,\n",
        " title={Federated learning via decentralized dataset distillation in resource-constrained edge environments},\n",
        " author={Song, Rui and Liu, Dai and Chen, Dave Zhenyu and Festag, Andreas and Trinitis, Carsten and Schulz, Martin and Knoll, Alois},\n",
        " journal={arXiv preprint arXiv:2208.11311},\n",
        " year={2022}\n",
        "}"
      ],
      "metadata": {
        "id": "kvonaDzF7bQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages"
      ],
      "metadata": {
        "id": "rer4yoFC5Dlu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjw7VsQsQ7n6",
        "outputId": "6b532767-6394-42d5-ef65-47c0599c619b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import tqdm\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "from torchvision.utils import save_image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ECE1512/ProjectB')\n",
        "import utils\n",
        "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
        "import networks\n"
      ],
      "metadata": {
        "id": "4oQeoI4NRo0U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "kJCU7q8sRrje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset = 'MNIST'\n",
        "mnist_data_path = './mnist_data'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = utils.get_dataset(mnist_dataset, mnist_data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDuCn4qHRs5x",
        "outputId": "97f8fda9-a141-4b97-f648-61add61b1d51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 125282385.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 27209275.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 255576178.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4165871.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "4jHpcV_m5Y7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citation:\n",
        "Rui Song, Dai Liu, Dave Zhenyu Chen, Andreas Festag, Carsten Trinitis, Martin Schulz, Alois C. Knoll:\n",
        "Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments. CoRR abs/2208.11311 (2022)"
      ],
      "metadata": {
        "id": "MdPuhy2D7CY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## (a) train and test"
      ],
      "metadata": {
        "id": "JEFmKEGrSfez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with real dataset initiation"
      ],
      "metadata": {
        "id": "bz0bNZAV6W7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class argument():\n",
        "  def __init__(self,device,ipc = 10):\n",
        "    self.model = 'ConvNet'\n",
        "    self.method = 'DM'\n",
        "    self.save_path = \"DM_MNISTresult\"\n",
        "    self.num_classes = num_classes\n",
        "    self.dataset = 'MNIST'\n",
        "    self.channel = channel\n",
        "    self.im_size = im_size\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "    self.ipc = ipc\n",
        "    self.Iteration = 200\n",
        "    self.num_epochs = 30\n",
        "    self.num_op_step = 1\n",
        "    self.lr_img = 1\n",
        "    self.lr_net = 0.01\n",
        "    self.epoch_eval_train = 2  #need be 20 as final test\n",
        "    self.batch_train = 256\n",
        "    self.batch_real =256\n",
        "    self.init = 'real'\n",
        "    self.outer_loop, self.inner_loop = utils.get_loops(self.ipc)\n",
        "    self.dis_metric = 'ours'\n",
        "    self.num_exp = 1\n",
        "    self.num_eval =20\n",
        "    self.epoch_eval_train = 30\n",
        "    self.device = device\n",
        "    self.dsa = False\n",
        "    self.dsa_param = utils.ParamDiffAug()\n",
        "    self.dc_aug_param = utils.get_daparam(self.dataset, model, NET, ipc = self.ipc)\n",
        "    self.dsa_strategy = self.dc_aug_param['strategy']\n",
        "\n",
        "args = argument(device, 10)\n",
        "\n"
      ],
      "metadata": {
        "id": "5SxVVQvCScIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "3447fe46-e102-4d90-bbf7-d3a78d72e6d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-25d25431f9f6>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsa_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdc_aug_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'strategy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NET = 'ConvNet'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = utils.get_network(NET,channel,num_classes).to(device)"
      ],
      "metadata": {
        "id": "o6yQg5K_Un2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "def Distribution_Matching(Net, args):\n",
        "  '''\n",
        "    itype:\n",
        "      Net -> str(): net type\n",
        "      image_syn ->\n",
        "      args -> obj: parameters\n",
        "    rtype:\n",
        "      data_save, visual_save, test_acc, train_acc -> list[],list[],list[],list[]\n",
        "  '''\n",
        "  if not os.path.exists(args.save_path):\n",
        "    os.mkdir(args.save_path)\n",
        "\n",
        "  eval_it_pool = list(range(0, args.Iteration + 1, 50))\n",
        "\n",
        "\n",
        "  accs_all_exps = dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ''' orgainize image part '''\n",
        "  indices_class = [[] for c in range(num_classes)]\n",
        "  images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
        "  labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
        "\n",
        "  for i, lab in enumerate(labels_all):\n",
        "      indices_class[lab].append(i)\n",
        "\n",
        "  images_all = torch.cat(images_all, dim=0).to(args.device)\n",
        "  labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
        "\n",
        "  for c in range(num_classes):\n",
        "      print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
        "\n",
        "  def get_images(c, n): # get random n images from class c\n",
        "      idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
        "      return images_all[idx_shuffle]\n",
        "\n",
        "  '''initialize the synthetic data '''\n",
        "  image_syn = torch.randn(size=(args.num_classes*args.ipc, args.channel, args.im_size[0], args.im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
        "  label_syn = torch.tensor([i // args.num_classes for i in range(args.num_classes * args.ipc)],dtype=torch.long, device=args.device)\n",
        "\n",
        "  if args.init == 'real':\n",
        "    print('initialize synthetic data from random real images')\n",
        "    for c in range(args.num_classes):\n",
        "      image_syn.data[c*args.ipc:(c+1)*args.ipc] = get_images(c, args.ipc).detach().data\n",
        "  else:\n",
        "    print('initialize synthetic data from random noise')\n",
        "\n",
        "  ''' train '''\n",
        "  data_save = []   #final syn-dataset (data_save[0][0] = images; data_save[0][1] = labels)\n",
        "  test_acc = []    #record test accuracy of every iteration\n",
        "  train_acc = []   #record train accuracy of every iteration\n",
        "  all_losses =[]\n",
        "\n",
        "  optimizer_img = torch.optim.SGD([image_syn, ], lr=args.lr_img, momentum=0.5)\n",
        "  optimizer_img.zero_grad()\n",
        "  criterion_img = nn.CrossEntropyLoss().to(args.device)\n",
        "  print('%s training begins'% get_time())\n",
        "\n",
        "  for it in range(args.Iteration+1):\n",
        "    ''' Evaluate synthetic data '''\n",
        "    if it in eval_it_pool:\n",
        "        ''' visualize and save '''\n",
        "        save_name = os.path.join(args.save_path, args.init+'vis_%s_%dipc_iter%d.png'%( args.dataset, args.ipc, it))\n",
        "        image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
        "        for ch in range(channel):\n",
        "            image_syn_vis[:, ch] = image_syn_vis[:, ch]  * std[ch] + mean[ch]\n",
        "        image_syn_vis[image_syn_vis<0] = 0.0\n",
        "        image_syn_vis[image_syn_vis>1] = 1.0\n",
        "        save_image(image_syn_vis, save_name, nrow=args.ipc) # Trying normalize = True/False may get better visual effects.\n",
        "\n",
        "\n",
        "    ''' train sythetic data'''\n",
        "    net = utils.get_network(NET,args.channel,args.num_classes, args.im_size).to(args.device)\n",
        "    net.train()\n",
        "    net_parameters = list(net.parameters())\n",
        "    for param in net_parameters:\n",
        "        param.requires_grad = False\n",
        "    embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed # for GPU parallel\n",
        "    loss_avg =0\n",
        "    loss = torch.tensor(0.0).to(args.device)\n",
        "    for c in range(num_classes):\n",
        "        img_real = get_images(c, args.batch_real)\n",
        "        img_syn = image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
        "\n",
        "        if args.dsa:\n",
        "            seed = int(time.time() * 1000) % 100000\n",
        "            img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
        "            img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
        "\n",
        "        output_real = embed(img_real).detach()\n",
        "        output_syn = embed(img_syn)\n",
        "\n",
        "        loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0))**2)\n",
        "\n",
        "\n",
        "    optimizer_img.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_img.step()\n",
        "    loss_avg += loss.item()\n",
        "\n",
        "    loss_avg /= (num_classes)\n",
        "\n",
        "    if it%10 == 0:\n",
        "        print('%s iter = %05d, loss = %.4f' % (get_time(), it, loss_avg))\n",
        "\n",
        "\n",
        "\n",
        "    ''' evaluate '''\n",
        "    if it in eval_it_pool:\n",
        "      args.epoch_eval_train = 20\n",
        "      net_eval = utils.get_network(NET, channel, num_classes, im_size).to(args.device) # get a random model\n",
        "      image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach())\n",
        "      _, acc_train, acc_test = utils.evaluate_synset(it, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
        "      test_acc.append(acc_test)\n",
        "      train_acc.append(acc_train)\n",
        "\n",
        "    '''Save the synthetic data result'''\n",
        "    if it == (args.Iteration-1):\n",
        "      data_save.append([copy.deepcopy(image_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
        "      torch.save({'data': data_save}, os.path.join(args.save_path, args.init+'res_%s_%dipc.pt'%(args.dataset, args.ipc)))\n",
        "      print(\"The Final Accuracy for the sythetic data result: \", str(test_acc[-1]))\n",
        "\n",
        "  return data_save, test_acc, train_acc\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JsZPvTynU2Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GCku_4XlmcpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = argument(device, 10)\n",
        "NET = \"ConvNet\"\n",
        "# image_syn, label_syn = init_syn(args, 'real')\n",
        "data_save,  test_acc, train_acc = Distribution_Matching(NET, args)"
      ],
      "metadata": {
        "id": "_WlsO4ucb_5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on the real dataset - real data initialization"
      ],
      "metadata": {
        "id": "18rKMIM5iQ-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.dataset = 'MNIST'\n",
        "it_eval = 20\n",
        "args.model = 'ConvNet'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "\n",
        "images_train = data_save[0][0].to(args.device)\n",
        "labels_train = data_save[0][1].to(args.device)\n",
        "dst_train = utils.TensorDataset(images_train, labels_train)\n",
        "_, acc_train, acc_test = utils.evaluate_synset(it_eval,net,images_train ,labels_train,testloader,args)\n",
        "print(\"test with synthetic dataset, accuracy = %.4f\"%(acc_test))"
      ],
      "metadata": {
        "id": "zgc3QBnNiMUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with Gaussain noise version"
      ],
      "metadata": {
        "id": "p9ORTkIgh93I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class argument():\n",
        "  def __init__(self,device,ipc = 10):\n",
        "    self.model = 'ConvNet'\n",
        "    self.method = 'DM'\n",
        "    self.save_path = \"DM_MNISTresult\"\n",
        "    self.num_classes = num_classes\n",
        "    self.dataset = 'MNIST'\n",
        "    self.channel = channel\n",
        "    self.im_size = im_size\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "    self.ipc = ipc\n",
        "    self.Iteration = 100\n",
        "    self.num_epochs = 30\n",
        "    self.num_op_step = 1\n",
        "    self.lr_img = 1\n",
        "    self.lr_net = 0.01\n",
        "    self.epoch_eval_train = 20\n",
        "    self.batch_train = 256\n",
        "    self.batch_real =256\n",
        "    self.init = 'noise'\n",
        "    self.outer_loop, self.inner_loop = utils.get_loops(self.ipc)\n",
        "    self.dis_metric = 'ours'\n",
        "    self.num_exp = 1\n",
        "    self.num_eval =20\n",
        "    self.epoch_eval_train = 30\n",
        "    self.device = device\n",
        "    self.dsa = False\n",
        "    self.dsa_param = utils.ParamDiffAug()\n",
        "    self.dc_aug_param = utils.get_daparam(self.dataset, model, NET, ipc = self.ipc)\n",
        "    self.dsa_strategy = self.dc_aug_param['strategy']\n",
        "\n",
        "args = argument(device, 10)\n",
        "\n"
      ],
      "metadata": {
        "id": "6q4CbD45jGpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argument(device, 10)\n",
        "NET = \"ConvNet\"\n",
        "# image_syn, label_syn = init_syn(args, 'real')\n",
        "gn_data_save,  gn_test_acc, gn_train_acc = Distribution_Matching(NET, args)"
      ],
      "metadata": {
        "id": "huXdNpPojQEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate in the real dataset - Gaussain noise version"
      ],
      "metadata": {
        "id": "v4uIDmUoiD1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.dataset = 'MNIST'\n",
        "it_eval = 10\n",
        "args.model = 'ConvNet'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "\n",
        "images_train = gn_data_save[0][0].to(args.device)\n",
        "labels_train = gn_data_save[0][1].to(args.device)\n",
        "dst_train = utils.TensorDataset(images_train, labels_train)\n",
        "_, acc_train, acc_test = utils.evaluate_synset(it_eval,net,images_train ,labels_train,testloader,args)\n",
        "print(\"test with synthetic dataset, accuracy = %.4f\"%(acc_test))"
      ],
      "metadata": {
        "id": "9dm72cKgiUUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b) Compare the performance\n",
        "To evaluate the performance here, we compare the generated images, and their performance with different models, all information is included in the report"
      ],
      "metadata": {
        "id": "m_q-crSa37S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.model = 'VGG11'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "images_train = data_save[0][0].to(args.device)\n",
        "labels_train = data_save[0][1].to(args.device)\n",
        "dst_train = utils.TensorDataset(images_train, labels_train)\n",
        "_, acc_train, acc_test = utils.evaluate_synset(it_eval,net,images_train ,labels_train,testloader,args)\n",
        "print(\"test with synthetic dataset, accuracy = %.4f\"%(acc_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Lmyms23-iH",
        "outputId": "4482685c-5104-40fa-bbc2-05566b83f63b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-01 04:18:09] Evaluate_10: epoch = 0020 train time = 0 s train loss = 1.961015 train acc = 0.5200, test acc = 0.6617\n",
            "test with synthetic dataset, accuracy = 0.6617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.model = 'VGG11'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "images_train = gn_data_save[0][0].to(args.device)\n",
        "labels_train = gn_data_save[0][1].to(args.device)\n",
        "dst_train = utils.TensorDataset(images_train, labels_train)\n",
        "_, acc_train, acc_test = utils.evaluate_synset(it_eval,net,images_train ,labels_train,testloader,args)\n",
        "print(\"test with synthetic dataset, accuracy = %.4f\"%(acc_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnB4LVq14Cl0",
        "outputId": "359d46e4-05d8-4269-f861-1b21a3f8bf2b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-01 04:18:12] Evaluate_10: epoch = 0020 train time = 0 s train loss = 1.911036 train acc = 0.5500, test acc = 0.6350\n",
            "test with synthetic dataset, accuracy = 0.6350\n"
          ]
        }
      ]
    }
  ]
}